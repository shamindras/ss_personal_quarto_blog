[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Welcome",
    "section": "",
    "text": "This is my personal website which contains info about my research and where I blog about various topics of interest in statistics and machine learning.\nPlease browse around, and feel free to leave a comment."
  },
  {
    "objectID": "posts/post-with-code/index.html",
    "href": "posts/post-with-code/index.html",
    "title": "Post With Code",
    "section": "",
    "text": "This is a post with executable code."
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "Since this post doesn‚Äôt specify an explicit image, the first image in the post will be used in the listing page of posts."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Welcome!",
    "section": "",
    "text": "This is my personal website which contains info about my research and where I blog about various topics of interest in statistics and machine learning.\nPlease browse around, and feel free to leave a comment."
  },
  {
    "objectID": "data/rmds/acknowledgment_profile_salil.html",
    "href": "data/rmds/acknowledgment_profile_salil.html",
    "title": "ss_personal_quarto_blog",
    "section": "",
    "text": "I‚Äôd like to thank Salil Shrotriya for taking my profile pic which is the preview image for this post."
  },
  {
    "objectID": "data/rmds/acknowledgment_preview_tidyfun_salil.html",
    "href": "data/rmds/acknowledgment_preview_tidyfun_salil.html",
    "title": "ss_personal_quarto_blog",
    "section": "",
    "text": "I‚Äôd like to thank Salil Shrotriya for creating the preview image for this post. The hex sticker png files were sourced from here"
  },
  {
    "objectID": "posts.html",
    "href": "posts.html",
    "title": "Blog Posts",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Author\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n  \n\n\n\n\nSharp constants for finite dimensional norms\n\n\n\n\n\n\n\nlinear algebra\n\n\nmath\n\n\nnorms\n\n\n\n\nA general result about deriving sharp constants for finite dimensional \\(\\ell_{p}\\)-norms\n\n\n\n\n\n\nMay 12, 2022\n\n\nShamindra Shrotriya\n\n\n\n\n\n\n  \n\n\n\n\nCharacterizing norm triangle inequalites via convexity\n\n\n\n\n\n\n\nlinear algebra\n\n\nmath\n\n\nnorms\n\n\n\n\nA simple approach to proving the triangle inequality for a given norm-like function using convexity.\n\n\n\n\n\n\nFeb 12, 2022\n\n\nShamindra Shrotriya\n\n\n\n\n\n\n  \n\n\n\n\nShamindra‚Äôs January 2020 Roundup\n\n\n\n\n\n\n\npersonal\n\n\nroundup\n\n\nrstats\n\n\nmath\n\n\n\n\nA quick roundup of any interesting January 2020 activities\n\n\n\n\n\n\nJan 27, 2020\n\n\nShamindra Shrotriya\n\n\n\n\n\n\n  \n\n\n\n\nShamindra‚Äôs September 2019 Roundup\n\n\n\n\n\n\n\npersonal\n\n\nroundup\n\n\nrstats\n\n\nmath\n\n\n\n\nA quick roundup of any interesting September 2019 activities\n\n\n\n\n\n\nSep 30, 2019\n\n\nShamindra Shrotriya\n\n\n\n\n\n\n  \n\n\n\n\nShamindra‚Äôs August 2019 Roundup\n\n\n\n\n\n\n\npersonal\n\n\nroundup\n\n\nrstats\n\n\nmath\n\n\n\n\nA quick roundup of any interesting August 2019 activities\n\n\n\n\n\n\nAug 31, 2019\n\n\nShamindra Shrotriya\n\n\n\n\n\n\n  \n\n\n\n\nTidyverse Fun - Part 2\n\n\n\n\n\n\n\ntidyverse\n\n\nrstats\n\n\n\n\nSecond part in a series of doing useful tasks with the Tidyverse. This time auto-generating sequential LaTeX newcommand macros\n\n\n\n\n\n\nAug 24, 2019\n\n\nShamindra Shrotriya\n\n\n\n\n\n\n  \n\n\n\n\nUpgrading Distill Blog Settings\n\n\n\n\n\n\n\ndistill\n\n\n\n\nThe second part of a series on how I upgraded this Distill themed blog\n\n\n\n\n\n\nJul 31, 2019\n\n\nShamindra Shrotriya\n\n\n\n\n\n\n  \n\n\n\n\nShamindra‚Äôs July 2019 Roundup\n\n\n\n\n\n\n\npersonal\n\n\nroundup\n\n\nrstats\n\n\nmath\n\n\n\n\nA quick roundup of any interesting July 2019 activities\n\n\n\n\n\n\nJul 30, 2019\n\n\nShamindra Shrotriya\n\n\n\n\n\n\n  \n\n\n\n\nReproducibility Challenge: Titanic Survivors Plot\n\n\n\n\n\n\n\ntidyverse\n\n\nrstats\n\n\nreproducibility\n\n\n\n\nUsing the Tidyverse to reproduce a plot on the survivorship of the Titanic\n\n\n\n\n\n\nJul 21, 2019\n\n\nShamindra Shrotriya\n\n\n\n\n\n\n  \n\n\n\n\nTidyverse Fun - Part 1\n\n\n\n\n\n\n\ntidyverse\n\n\nrstats\n\n\n\n\nFirst part in a series of doing useful tasks with the tidyverse. This time, we generate Oxford Comma triples, and sequentially numbered BibTeX entries\n\n\n\n\n\n\nJul 15, 2019\n\n\nShamindra Shrotriya\n\n\n\n\n\n\n  \n\n\n\n\nSetting up a Distill Blog with Netlify\n\n\n\n\n\n\n\ndistill\n\n\n\n\nFirst part of a series on how I setup this distill themed blog with Netlify\n\n\n\n\n\n\nJul 11, 2019\n\n\nShamindra Shrotriya\n\n\n\n\n\n\n  \n\n\n\n\nWelcome to Shamindra‚Äôs Site\n\n\n\n\n\n\n\npersonal\n\n\n\n\nDetailing interesting things in the life of a PhD statistics student at CMU\n\n\n\n\n\n\nJul 10, 2019\n\n\nShamindra Shrotriya\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/2019-07-10-shrotriya2019welcome/shrotriya2019welcome.html",
    "href": "posts/2019-07-10-shrotriya2019welcome/shrotriya2019welcome.html",
    "title": "Welcome to Shamindra‚Äôs Site",
    "section": "",
    "text": "Hi there! I‚Äôm Shamindra Shrotriya, a graduate student in the Department of Statistics and Data Science at the wonderful Carnegie Mellon University. I‚Äôve decided to start blogging to document my learning and development in statistics as a graduate student.\nI‚Äôd like it to be a fun place to document interesting things I like to read about in the statistics and machine learning space (statistical theory/methodology, research, rstats, python ‚Ä¶) as well as anything else I am generally into e.g.¬†books, sports etc.\nFeel free to pull up a chair, leave a comment, and join me so that we can explore together.\nMy CV can be found here."
  },
  {
    "objectID": "posts/2019-07-10-shrotriya2019welcome/shrotriya2019welcome.html#credits",
    "href": "posts/2019-07-10-shrotriya2019welcome/shrotriya2019welcome.html#credits",
    "title": "Welcome to Shamindra‚Äôs Site",
    "section": "Credits",
    "text": "Credits\nThe credit to starting this blog goes to the following people. I hope to not disappoint and create some useful content here üññ.\n\nYihui Xie, JJ Allaire and Rich Iannone - for co-developing the fantastic distill package which upon which this blog/ site is based\nRachel Thomas for posting this fantastic blog post encouraging people like me to (finally!) create a blog\nMy parents for encouraging to communicate my passion for statistics. I secretly think that this is their way of minimizing my passionate rants about the bootstrap in our regular Skype chats (the rants will still continue though‚Ä¶)."
  },
  {
    "objectID": "posts/2019-07-10-shrotriya2019welcome/index.html",
    "href": "posts/2019-07-10-shrotriya2019welcome/index.html",
    "title": "Welcome to Shamindra‚Äôs Site",
    "section": "",
    "text": "Hi there! I‚Äôm Shamindra Shrotriya, a graduate student in the Department of Statistics and Data Science at the wonderful Carnegie Mellon University. I‚Äôve decided to start blogging to document my learning and development in statistics as a graduate student.\nI‚Äôd like it to be a fun place to document interesting things I like to read about in the statistics and machine learning space (statistical theory/methodology, research, rstats, python ‚Ä¶) as well as anything else I am generally into e.g.¬†books, sports etc.\nFeel free to pull up a chair, leave a comment, and join me so that we can explore together.\nMy CV can be found here."
  },
  {
    "objectID": "posts/2019-07-10-shrotriya2019welcome/index.html#credits",
    "href": "posts/2019-07-10-shrotriya2019welcome/index.html#credits",
    "title": "Welcome to Shamindra‚Äôs Site",
    "section": "Credits",
    "text": "Credits\nThe credit to starting this blog goes to the following people. I hope to not disappoint and create some useful content here üññ.\n\n\nYihui Xie, JJ Allaire and Rich Iannone - for co-developing the fantastic distill package which upon which this blog/ site is based\n\nRachel Thomas for posting this fantastic blog post encouraging people like me to (finally!) create a blog\n\nMy parents for encouraging to communicate my passion for statistics. I secretly think that this is their way of minimizing my passionate rants about the bootstrap in our regular Skype chats (the rants will still continue though‚Ä¶)."
  },
  {
    "objectID": "posts/2019-07-10-shrotriya2019welcome/index.html#acknowledgments",
    "href": "posts/2019-07-10-shrotriya2019welcome/index.html#acknowledgments",
    "title": "Welcome to Shamindra‚Äôs Site",
    "section": "Acknowledgments",
    "text": "Acknowledgments\nI‚Äôd like to thank Salil Shrotriya for taking my profile pic which is the preview image for this post."
  },
  {
    "objectID": "data/qmds/acknowledgment_preview_tidyfun_salil.html",
    "href": "data/qmds/acknowledgment_preview_tidyfun_salil.html",
    "title": "Shamindra Shrotriya",
    "section": "",
    "text": "I‚Äôd like to thank Salil Shrotriya for creating the preview image for this post. The hex sticker png files were sourced from here"
  },
  {
    "objectID": "data/qmds/acknowledgment_profile_salil.html",
    "href": "data/qmds/acknowledgment_profile_salil.html",
    "title": "Untitled",
    "section": "",
    "text": "I‚Äôd like to thank Salil Shrotriya for taking my profile pic which is the preview image for this post."
  },
  {
    "objectID": "posts/2019-07-11-shrotriya2019distillpt1/index.html",
    "href": "posts/2019-07-11-shrotriya2019distillpt1/index.html",
    "title": "Setting up a Distill Blog with Netlify",
    "section": "",
    "text": "This is a meta blogpost to describe how I setup this personal academic blog. It is based on the relatively new distill package by the RStudio team. The main tools used I used to create this blog are:\n\nMy personal Github account\n\nThe RStudio editor\n\nThe R packages distill and here\n\nA macbook pro (2017 edition) and the iterm2 terminal\nMy personal netlify account and also my personal domain bought from Google Domains\n\n\nThe details of how I used the tools used are all noted below in a step-by-step manner.\nImportantly, I should note that the RStudio distill team has already created an excellent distill blog creation tutorial which I thoroughly used and highly recommend to new users. I wrote this meta blogpost in my own words so that I can personally remember the details going forward. I also added more details on deployment with Google Domains and Netlify that would hopefully be useful to new R users waiting to deploy a similar distill blog.\nAdmittedly this blogpost is verbose, but hopefully the details help users new to the distill blogging package."
  },
  {
    "objectID": "posts/2019-07-11-shrotriya2019distillpt1/index.html#step-1-create-new-distill-blog-repo",
    "href": "posts/2019-07-11-shrotriya2019distillpt1/index.html#step-1-create-new-distill-blog-repo",
    "title": "Setting up a Distill Blog with Netlify",
    "section": "Step 1: Create new distill blog repo",
    "text": "Step 1: Create new distill blog repo\nI opted to manage my blog versioning using Git/Github. I started by going to my personal github account and create a new repository. I called mine ss_personal_distill_blog and also initialized it with a README.md and included an .gitignore for R since that will the blogging language of choice here üòÑ. This is shown in the screenshot below.\n\n\nSetting up the Site Github repo\n\n\nOptions for creating the Github repo for the distill blog\nOnce created the repo will appear in github as seen in the following screenshot\n\n\nNew Site Github repo with README.md\n\n\nNewly created Github repo for the distill blog"
  },
  {
    "objectID": "posts/2019-07-11-shrotriya2019distillpt1/index.html#step-2-clone-the-repo-locally",
    "href": "posts/2019-07-11-shrotriya2019distillpt1/index.html#step-2-clone-the-repo-locally",
    "title": "Setting up a Distill Blog with Netlify",
    "section": "Step 2: Clone the repo locally",
    "text": "Step 2: Clone the repo locally\nWith the github repo created, I switched locally on my mac to iterm2 terminal and cloned the repo locally using the following command:\n\ngit clone git@github.com:shamindras/ss_personal_distill_blog.git\n\nAnd the cloning quickly finished with the following output\nCloning into 'ss_personal_distill_blog'...\nremote: Enumerating objects: 4, done.\nremote: Counting objects: 100% (4/4), done.\nremote: Compressing objects: 100% (4/4), done.\nremote: Total 4 (delta 0), reused 0 (delta 0), pack-reused 0\nReceiving objects: 100% (4/4), done.\nNow I simply changed into the newly cloned blog directory by running the following terminal command:\n\ncd ss_personal_distill_blog\n\nI then ran the following terminal command:\n\ntree\n\nThis resulted in the following directory structure so far:\n.\n‚îú‚îÄ‚îÄ .git\n‚îú‚îÄ‚îÄ .gitignore\n‚îî‚îÄ‚îÄ README.md\nGreat, now the repo was setup locally. At this stage there is just a simple README.md which will get added to a bit later, but the main focus is to start creating the distill blog within this directory locally."
  },
  {
    "objectID": "posts/2019-07-11-shrotriya2019distillpt1/index.html#step-3-create-the-distill-blog-files",
    "href": "posts/2019-07-11-shrotriya2019distillpt1/index.html#step-3-create-the-distill-blog-files",
    "title": "Setting up a Distill Blog with Netlify",
    "section": "Step 3: Create the distill blog files",
    "text": "Step 3: Create the distill blog files\nIn order to start creating the blog contents I opened up an instance of RStudio from within my new directory on my macbook via the following terminal command:\n\nopen -a /Applications/RStudio.app .\n\nNote: The . at the end of the command ensures that RStudio opens in this newly created blog directory\nWith RStudio opened we can now run the following R commands in just the console to create the install the required and distill blog setup packages:\n\nreq_pckgs <- c(\"distill\", \"here\")\ninstall.packages(pkgs = req_pckgs)\nlibrary(here)\nlibrary(distill)\n\nNow we can create our blog using the following 2 commands from the freshly installed distill package using the following command run in the console\n\ndistill::create_blog(dir = here::here(),\n                     title = \"Shamindra's Shrotriya's blog\",\n                     gh_pages = TRUE)\n\nNote that we set gh_pages = TRUE to ensure that we can host this blog on github pages down the line if needed. You can omit this if you don‚Äôt want the option to have github pages as your host in the future. I will be using Netlify to host my blog (see below), but it is good to have an additional host option in the future.\nMy local distill blog directory now looked like this (again after running the tree command in the terminal):\n.\n‚îú‚îÄ‚îÄ .git\n‚îú‚îÄ‚îÄ .gitignore\n‚îú‚îÄ‚îÄ .nojekyll\n‚îú‚îÄ‚îÄ README.md\n‚îú‚îÄ‚îÄ _posts\n‚îú‚îÄ‚îÄ _site.yml\n‚îú‚îÄ‚îÄ about.Rmd\n‚îú‚îÄ‚îÄ docs\n‚îú‚îÄ‚îÄ index.Rmd\n‚îî‚îÄ‚îÄ ss_personal_distill_blog.Rproj\nPretty cool! Note that there is a newly created _posts directory for future blogposts. And there is a directory called docs to store all our processed blogposts later. If we had set gh_pages = FALSE the docs directory would be automatically replaced by a _site directory. More on this point later."
  },
  {
    "objectID": "posts/2019-07-11-shrotriya2019distillpt1/index.html#step-4-customize-the-welcome-blogpost",
    "href": "posts/2019-07-11-shrotriya2019distillpt1/index.html#step-4-customize-the-welcome-blogpost",
    "title": "Setting up a Distill Blog with Netlify",
    "section": "Step 4: Customize the welcome blogpost",
    "text": "Step 4: Customize the welcome blogpost\nSo distill already had us underway with a default welcome blogpost contained in the welcome.Rmd file for us. There are a bunch of javascript related files automatically generated in the _posts/welcome/welcome_files directory but these don‚Äôt need to be altered by the user. I just needed to modify welcome.Rmd contents per my preference as with any regular Rmd file and click Knit in RStudio to refresh it. We can see this in the _posts directory:\n./_posts/welcome\n‚îú‚îÄ‚îÄ welcome.Rmd\n‚îú‚îÄ‚îÄ welcome.html\n‚îî‚îÄ‚îÄ welcome_files\nOne thing that slightly bothered me is that the default welcome blogpost has no date prefix in the directory. This would be nice to have in order to sort all future blogposts chronologically. I could‚Äôve modified this default welcome blogpost Rmd and directory to include the date prefix manually. For simplicity I opted to delete the default welcome directory altogether and recreated it with the date prefix as I prefer as detailed below.\nTo delete the default welcome directory, I just ran the following code at my terminal:\n\nrm -rf _posts/welcome\n\nNote: ‚ö†Ô∏è Always be careful using rm -rf\nWith the default welcome blogpost deleted, I created my own custom welcome blogpost as follows:\n\ndistill::create_post(title = \"Welcome to Shamindra‚Äôs Blog\",\n                     author = \"Shamindra Shrotriya\",\n                     date_prefix = TRUE)\n\nNow the welcome blogpost has this nice date prefix structure since we passed this option as TRUE. Let‚Äôs see what the _posts directory looks like now\n_posts/2019-07-10-welcome-to-shamindras-blog\n‚îî‚îÄ‚îÄ welcome-to-shamindras-blog.Rmd`\nNeat - just how I like it! I then modified the content of the new welcome blogpost by going to the following file:\n_posts/2019-06-21-welcome-to-shamindras-blog/welcome-to-shamindras-blog.Rmd\nI modified the contents and then knitted the Rmd file once done to refresh and save the contents.\nNow I had locally created my first personalized content, a simple welcome post üòé.\nMy welcome blog entry can be found here for reference."
  },
  {
    "objectID": "posts/2019-07-11-shrotriya2019distillpt1/index.html#step-5-customize-your-blog-layout",
    "href": "posts/2019-07-11-shrotriya2019distillpt1/index.html#step-5-customize-your-blog-layout",
    "title": "Setting up a Distill Blog with Netlify",
    "section": "Step 5: Customize your blog layout",
    "text": "Step 5: Customize your blog layout\nNow I needed to customize the blog header banner and setup links and update contents as required.\nWe will start with the _site.yml contents which controls the page layout. I modified the _site.yml file which contains default metadata settings for the blog to have the following contents:\nname: \"test_distill_blog\"\ntitle: \"Shamindra's Blog\"\ndescription: |\n  Shamindra Shrotriya's personal blog/ site. Some fun posts\n  on math, statistics and the PhD student life.\noutput_dir: \"_site\"\nnavbar:\n  right:\n    - text: \"Home\"\n      href: index.html\n    - text: \"About\"\n      href: about.html\n    - icon: fa fa-rss\n      href: index.xml\ncollections:\n  posts:\n    share: [twitter, linkedin]\nbase_url: https://www.shamindras.com/\noutput: distill::distill_article\nMy _site.yml file can be found here for reference.\nI updated the About.Rmd file as required and knit it. This is a default Rmd that distill conveniently creates this file to give readers some background on the site purpose and of course about the author.\nMy About.Rmd file can be found here for reference.\nNo need to update the default distill Index.Rmd file that is automatically created. I simply opened it and knit it manually in RStudio to update the site contents.\nI also updated the README.md to add some useful information (for any users who stumble onto the github page) and saved it. No need to knit anything here as it is a simple markdown file.\nMy README.md can be found here for reference.\nNow in Rstudio I just knit the welcome.Rmd post and also ran the following command in the console\n\nrmarkdown::render_site(input = here::here())\n\nThe locally created distill blog was now created and rendered and looked like this in the RStudio viewer pane:\n\n\nNewly Created Distill Blog (local)\n\n\nPretty cool - I now had a working local version of our blog in RStudio."
  },
  {
    "objectID": "posts/2019-07-11-shrotriya2019distillpt1/index.html#step-6-commit-and-push-changes-to-github",
    "href": "posts/2019-07-11-shrotriya2019distillpt1/index.html#step-6-commit-and-push-changes-to-github",
    "title": "Setting up a Distill Blog with Netlify",
    "section": "Step 6: Commit and push changes to github",
    "text": "Step 6: Commit and push changes to github\nNote that all our changes are so far in our local git repo. We need to get this blog online! A first step is to commit and push them to our github repo. I did this in my local directory in the terminal as follows: in git at my terminal as follows:\n\ngit add -A # Add all new changes\ngit commit -m \"ENH: Created welcome post with date prefix, deleted default post\"\ngit push origin master\n\nAnd the changes are now reflected in the github master branch!"
  },
  {
    "objectID": "posts/2019-07-11-shrotriya2019distillpt1/index.html#step-7-buy-a-domain-name-optional",
    "href": "posts/2019-07-11-shrotriya2019distillpt1/index.html#step-7-buy-a-domain-name-optional",
    "title": "Setting up a Distill Blog with Netlify",
    "section": "Step 7: Buy a Domain name (optional)",
    "text": "Step 7: Buy a Domain name (optional)\nAlthough the blog was our blog contents are in a public online place i.e. github, I just needed to link it to a service that deploys websites from github. But first I needed to go buy a domain name for my blog. I went to Google Domains and bought www.shamindras.com for about $15/yr.\nThere are free alternatives e.g.¬†Github Pages, but I wanted to have ownership on my page and found the annual fee to be reasonable with Google Domains."
  },
  {
    "objectID": "posts/2019-07-11-shrotriya2019distillpt1/index.html#step-8-deploy-your-website-with-netlify",
    "href": "posts/2019-07-11-shrotriya2019distillpt1/index.html#step-8-deploy-your-website-with-netlify",
    "title": "Setting up a Distill Blog with Netlify",
    "section": "Step 8: Deploy your website with Netlify",
    "text": "Step 8: Deploy your website with Netlify\nNow that the domain name is bought, I just needed to deploy the newly created blog contents on the registered domain name. Enter netlify! This is a free (and awesome) deployment service. I created a personal account following the intructions on Netlify website.\nI then logged in to Netlify and clicked on the green New site from Git button to get started. In the following menu I clicked the Github Continuous Deployment icon:\n\n\nCreating New Site with Netlify\n\n\nI then manually searched for my blog repo i.e.¬†ss_personal_distill_blog. Initially this did not appear, so I clicked the green Configure the Netlify app on GitHub link at the bottom and gave Netlify permissions to access this site. This is so Netlify can automatically sync with the github repo and deploy changes going forward as I make them directly to my github blog repo.\n\n\nGiving Netlify New Github repo Access\n\n\nI clicked on my site that appears and then ensured that I selected to ensure that the Branch to Deploy option is set to master.\n\n\nConfiguring Netlify Build Options\n\n\nThis simply means that netlify will only build the site based on what happens in my master branch in my github repo\nI then clicked Deploy Site and then saw the following deployment settings:\n\n\nDefault Netlify Site Name\n\n\nI clicked thee Site Settings button. Looks like my site name on Netlify is goofy-babbage-7f05c8. Cute, though I‚Äôll personalize by clicking the Change Site Name button. I changed it to ss-personal-distill-blog for my easy reference.\nI clicked the Build and Deploy button next and after clicking the Edit Settings button modified the Publish directory to be _site as shown below:\n\n\nSetup Continuous Deployment with Netlify\n\n\nThis is where all our blogposts in our github repo will be rendered to html by distill once we knit them. Netlify will just pick them up from here everytime you refresh them and deploy our website accordingly\nNext I need to manage the domain i.e.¬†tell Netlify to deploy my site on the custom domain I just purchased from Google Domains.\n\n\nCustomize Site Domains with Netlify\n\n\nAfter clicking verify we have the following domains now set, with www.shamindras.com being the primary domain.\n\n\nAll Custom Domains for Site with Netlify\n\n\nNetlify also tells me that the truncated url shamindras.com will also get routed to the blog. So I don‚Äôt event need to write the www. going forward. Thanks Netlify üôá‚Äç‚ôÄ."
  },
  {
    "objectID": "posts/2019-07-11-shrotriya2019distillpt1/index.html#step-9-patiently-wait-for-deployment",
    "href": "posts/2019-07-11-shrotriya2019distillpt1/index.html#step-9-patiently-wait-for-deployment",
    "title": "Setting up a Distill Blog with Netlify",
    "section": "Step 9: Patiently wait for deployment",
    "text": "Step 9: Patiently wait for deployment\nWith everything setup and configured on github/Netlify the deployment should be near instantaneous. But after about 20 mins my blog appeared at www.shamindras.com. So effectively Netlify and github were now talking to each other and site is setup!"
  },
  {
    "objectID": "posts/2019-07-11-shrotriya2019distillpt1/index.html#step-10-future-additions-and-extras",
    "href": "posts/2019-07-11-shrotriya2019distillpt1/index.html#step-10-future-additions-and-extras",
    "title": "Setting up a Distill Blog with Netlify",
    "section": "Step 10: Future additions and extras",
    "text": "Step 10: Future additions and extras\nNow that the blog/site is created there are a number of features I‚Äôd like to add. The most important being more blogposts and personal content. However it would also be nice to have the following features:\n\nDocumenting a general distill blogging workflow\nSetting up Disqus to enable user comments on blogposts\nHow to setup Blog Gallery for featured posts\nHow to setup an email subscription service for this blog\nHow to setup Google Analytics service for basic user activity tracking\n\nI will make sure to document the setup process as part of a series of future blog posts"
  },
  {
    "objectID": "posts/2019-07-11-shrotriya2019distillpt1/index.html#concluding-thoughts",
    "href": "posts/2019-07-11-shrotriya2019distillpt1/index.html#concluding-thoughts",
    "title": "Setting up a Distill Blog with Netlify",
    "section": "Concluding Thoughts",
    "text": "Concluding Thoughts\nIf you managed to read this far, then I sincerely thank you. I hope to make even better technical and personal blogposts going forward. Please feel free to leave a friendly comment below for any questions you may have or any feedback for future blogposts."
  },
  {
    "objectID": "posts/2019-07-15-shrotriya2019tidyfunpt1/index.html",
    "href": "posts/2019-07-15-shrotriya2019tidyfunpt1/index.html",
    "title": "Tidyverse Fun - Part 1",
    "section": "",
    "text": "Based on a fun conversation with my statistics cohort over dinner we got to discussing the famous Oxford Comma (or Serial Comma depending on your persuasion). I‚Äôve never really adopted the use but my friends made a compelling argument on it‚Äôs apparent general lack of ambiguity when applied appropriately.\nWe will use the Oxford comma on the famously ambiguous phrase (here used without the Oxford Comma before leaves):\n\nEats, shoots and leaves\n\nAfter adding in the Oxford Comma this would become:\n\nEats, shoots, and leaves\n\nGoal: A fun experiment would be to generate all permutations of this phrase with and without the Oxford Comma using R and specifically the tidyverse packages.\n\nFirst, let‚Äôs load our required packages.\n\nlibrary(knitr)\nlibrary(magrittr)\nlibrary(tidyverse)\nlibrary(glue)\n\nLet‚Äôs also define our unique global word values used to construct the required phrases:\n\nWORD_VALS <- c(\"eats\", \"shoots\", \"leaves\")\n\nGenerate all unique 3-word permutations without replacement from the three unique words. We‚Äôll create a helper function to check that a vector of words is unique.\n\nis_unq_perm <- function(word1, word2, word3){\n    words_vec <- c(word1, word2, word3)\n    return(length(words_vec) - length(unique(words_vec)) == 0)\n}\n\nWe can now simply generate every possible triple with replacement using the tidyr::crossing function. We proceed to filter these \\(3^3 = 27\\) triples for unique triples using our is_unq_perm helper function applied row-by-row using purrr::pmap_lgl. The _lgl simply returns a TRUE/FALSE logical value as intended by the applied function.\nNote: The tidyr::crossing generates a Cartesian product of all the 3 word triples, very handy\n\n# Generate the unique word-triples\nall_perms <- tidyr::crossing(word1 = WORD_VALS,\n                             word2 = WORD_VALS,\n                             word3 = WORD_VALS) %>%\n                mutate(.data = .,\n                       is_unq_perm = purrr::pmap_lgl(.l = .,\n                                                     is_unq_perm)) %>%\n                filter(.data = ., is_unq_perm) %>%\n                select(-is_unq_perm)\n\n# Display output in a nice centered table\nall_perms %>%\n  kable(x = ., align = 'c',\n        col.names = c(\"Word 1\",\n                      \"Word 2\",\n                      \"Word 3\"))\n\n\n\nWord 1\nWord 2\nWord 3\n\n\n\neats\nleaves\nshoots\n\n\neats\nshoots\nleaves\n\n\nleaves\neats\nshoots\n\n\nleaves\nshoots\neats\n\n\nshoots\neats\nleaves\n\n\nshoots\nleaves\neats\n\n\n\n\n\nGreat - that part is done! Now we just need to generate for each triple of words an oxford comma and non-oxford comma version. This is done easily using the amazing glue package as seen below:\n\nexprs <- all_perms %>%\n          mutate(non_oxford_comma =\n                   glue_data(.x = .,\n                             \"{word1}, {word2} and {word3}\"),\n                 oxford_comma =\n                   glue_data(.x = .,\n                             \"{word1}, {word2}, and {word3}\")) %>%\n          select(non_oxford_comma, oxford_comma)\n\nWe can display the side-by-side output of the Non-Oxford Comma vs.¬†Oxford comma for the \\(6\\) generated triples as follows:\n\n# Display output in a nice centered table\nexprs %>%\n  kable(x = .,\n        align = 'c',\n        col.names = c(\"Non-Oxford Comma\",\n                      \"Oxford Comma\"))\n\n\n\nNon-Oxford Comma\nOxford Comma\n\n\n\neats, leaves and shoots\neats, leaves, and shoots\n\n\neats, shoots and leaves\neats, shoots, and leaves\n\n\nleaves, eats and shoots\nleaves, eats, and shoots\n\n\nleaves, shoots and eats\nleaves, shoots, and eats\n\n\nshoots, eats and leaves\nshoots, eats, and leaves\n\n\nshoots, leaves and eats\nshoots, leaves, and eats\n\n\n\n\n\nSo there you have it. Have fun generating your own version of Oxford Comma triples to engage in civil discussions with your fellow grammar focused friends üòÑ."
  },
  {
    "objectID": "posts/2019-07-15-shrotriya2019tidyfunpt1/index.html#task-2-generating-sequentially-numbered-bibtex-entries",
    "href": "posts/2019-07-15-shrotriya2019tidyfunpt1/index.html#task-2-generating-sequentially-numbered-bibtex-entries",
    "title": "Tidyverse Fun - Part 1",
    "section": "Task 2: Generating Sequentially Numbered BibTeX Entries",
    "text": "Task 2: Generating Sequentially Numbered BibTeX Entries\n\nThe central problem\nIn this case I needed to generate several BibTeX entries of the form:\n@misc{doe2019_lec1,\nauthor        = {Doe, John},\ntitle         = {Lecture Note 1 - STAT10A},\nmonth         = {March},\nyear          = {2018},\nurl           = {https://statschool/~doe/stats10A/Lectures/Lecture01.pdf},\n}\nAs it can be seen the lectures are numbered sequentially and change in the main BibTeX id, the title, and the url field.\nSpecifically I needed to construct 30 such sequential entries for lectures 1-30. Rather than do this manually, I realized that this would be fun scripting exercise with using the tidyverse packages glue, purrr, and stringr.\nGoal: Create 30 such BibTeX entries and print to the console to directly-copy paste to my BibTeX file.\n\n\nThe tidy approach\nFirst step is to write a function that takes a lecture number (integer) as an input and then outputs a single BibTeX entry for that lecture.\n\n# Generate BibTeX entry for a single lecture number\nget_lec_bibtex <- function(lec_num){\n  # Get the 2 character padded lecture number i.e. 1 -> \"01\"\n  lec_num_pad <- str_pad(string = lec_num, width = 2,\n                         side = \"left\", pad = \"0\")\n\n  # Construct the BibTeX entry\n  out_bbtex_str <- glue(\n    \"@misc{doe2019_lec<lec_num>,\n    author = {Doe, John},\n    title  = {Lecture Note <lec_num> - STAT10A},\n    month  = {March},\n    year   = {2018},\n    url    = {https://www.hpg/~doe/st10A/lecs/lec<lec_num_pad>.pdf}}\",\n    .open = \"<\",\n    .close = \">\")\n\n  return(out_bbtex_str)\n}\n\nNote that by default glue allows you to substitute input text in between { and } markers. However BibTeX entries already have literal default {} tags that we need to include in our function output. Rather than escaping them the glue package conveniently allows us to change the default opening and closing markers üíØ! We simply set these to be angle brackets < > using the .open and .close options above.\n\nNote: Luckily we don‚Äôt have literal angle brackets in our BibTeX output to deal with here\n\nLet‚Äôs just test this out quickly:\n\nlec_no <- 1\nget_lec_bibtex(lec_num = lec_no)\n\n@misc{doe2019_lec1,\nauthor = {Doe, John},\ntitle  = {Lecture Note 1 - STAT10A},\nmonth  = {March},\nyear   = {2018},\nurl    = {https://www.hpg/~doe/st10A/lecs/lec01.pdf}}\n\n\nGreat - looks like it is working as required with the correct string padding in the lecture number in the pdf filename!\n\nNote: We used the stringr str_pad to convert 1 to \"01\"\n\n\n\nApply to all lectures using purrr\nLet‚Äôs finish this by creating all the entries using purrr:\n\nlec_nums <- c(1, 30)\nlec_nums %>%\n  map_chr(.x = ., .f = ~get_lec_bibtex(lec_num = .x)) %>%\n  cat(., sep = \"\\n\\n\")\n\n@misc{doe2019_lec1,\nauthor = {Doe, John},\ntitle  = {Lecture Note 1 - STAT10A},\nmonth  = {March},\nyear   = {2018},\nurl    = {https://www.hpg/~doe/st10A/lecs/lec01.pdf}}\n\n@misc{doe2019_lec30,\nauthor = {Doe, John},\ntitle  = {Lecture Note 30 - STAT10A},\nmonth  = {March},\nyear   = {2018},\nurl    = {https://www.hpg/~doe/st10A/lecs/lec30.pdf}}\n\n\nYay - this works as expected! We can now paste into BibTeX as required.\nNote that we only created it for lectures 1 and 30 for easy scrolling. But for all lectures we can just replace c(1, 30) with 1:30 in the above code."
  },
  {
    "objectID": "posts/2019-07-15-shrotriya2019tidyfunpt1/index.html#conclusion",
    "href": "posts/2019-07-15-shrotriya2019tidyfunpt1/index.html#conclusion",
    "title": "Tidyverse Fun - Part 1",
    "section": "Conclusion",
    "text": "Conclusion\nThis post was for me to document and serve as a guide to automating a couple of fun text-based tasks that I came across in my work (and social life!). Using the tidy framework can be a fun way to solve these tasks (but certainly not the only way in R). Have fun playing around with the above and please post in the comments any questions/feedback you may have üëç.\nStay tuned for more blogposts solving more such tasks."
  },
  {
    "objectID": "posts/2019-07-15-shrotriya2019tidyfunpt1/index.html#acknowledgments",
    "href": "posts/2019-07-15-shrotriya2019tidyfunpt1/index.html#acknowledgments",
    "title": "Tidyverse Fun - Part 1",
    "section": "Acknowledgments",
    "text": "Acknowledgments\n\nI‚Äôd like to thank Salil Shrotriya for creating the preview image for this post. The hex sticker png files were sourced from here."
  },
  {
    "objectID": "posts/2019-07-21-shrotriya2019reprtitanic/shrotriya2019reprtitanic.html",
    "href": "posts/2019-07-21-shrotriya2019reprtitanic/shrotriya2019reprtitanic.html",
    "title": "Reproducibility Challenge: Titanic Survivors Plot",
    "section": "",
    "text": "In the February 2019 issue of Significance Magazine notably featured a story of the titanic disaster (Friendly, Symanzik, and Onder 2019) and visualization of key survival statistics. As a fan of R and data visualization I enjoyed this article and recommended it to anyone with similar interests. Although the subject is rather tragic, by reading the article I did get a better appreciation of how the information of the crash survivorship was conveyed to the general public through data visualization.\n\n\ncover"
  },
  {
    "objectID": "posts/2019-07-21-shrotriya2019reprtitanic/shrotriya2019reprtitanic.html#reproducibility-challenge",
    "href": "posts/2019-07-21-shrotriya2019reprtitanic/shrotriya2019reprtitanic.html#reproducibility-challenge",
    "title": "Reproducibility Challenge: Titanic Survivors Plot",
    "section": "Reproducibility Challenge",
    "text": "Reproducibility Challenge\nOf particular note in the article was the following data visualization poster printed shortly after the tragedy:\n\n\na\n\n\nI found this to be a very cool data visualization of the survivorship by class, gender, and adulthood. As a statistics graduate student, I care a lot about reproducibility of results not only as a basic check, but to really appreciate the results and more importantly any implicit assumptions behind the results. So this led to the following goal and effectively this blogpost:\nNote: Replicability is better, but reproducibility is a good start and often a more practically feasible undertaking\nGoal: Given the same Titanic survivors data could we recreate a similar looking chart using R and specifically the tidyverse set of tools?"
  },
  {
    "objectID": "posts/2019-07-21-shrotriya2019reprtitanic/shrotriya2019reprtitanic.html#collecting-and-cleaning-the-data",
    "href": "posts/2019-07-21-shrotriya2019reprtitanic/shrotriya2019reprtitanic.html#collecting-and-cleaning-the-data",
    "title": "Reproducibility Challenge: Titanic Survivors Plot",
    "section": "Collecting and cleaning the data",
    "text": "Collecting and cleaning the data\nFirst let‚Äôs begin by loading our required data cleaning and plotting packages. First we will load the required libraries needed for the analysis.\n\nlibrary(knitr)\nlibrary(tidyverse)\nlibrary(janitor)\nlibrary(plotly)\n\nIn the article the authors cite several resources for collecting the data for this task. Per the article we note that the data is already pre-baked into R and located in datasets::Titanic when R loads, which is convenient üòé.\nWe can source the data and start cleaning it for our exploration, using the handy clean_names function for column name cleaning and converting various categorical variables (age, sex, survivorship, and passenger class) to factors for easy plotting later.\n\n# Basic cleaning of names and filtering out non-zero counts\nt1 <- datasets::Titanic %>%\n        as_tibble() %>%\n        clean_names(dat = .) %>%\n        filter(.data = ., n != 0) %>%\n        mutate(.data = .,\n                      new_sex = ifelse(age == \"Child\", age, sex),\n                      n_sgnd = ifelse(survived == \"No\", -1*n, n)) %>%\n        select(class, new_sex, survived, n_sgnd)\n\n# Passenger (non-crew) level aggregation\nt2 <- t1 %>%\n        filter(class != \"Crew\") %>%\n        mutate(class = \"Pass.\") %>%\n        group_by(class, new_sex, survived) %>%\n        summarize(n_sgnd = sum(n_sgnd))\n\n`summarise()` has grouped output by 'class', 'new_sex'. You can override using\nthe `.groups` argument.\n\n# Crew (non-passenger) level aggregation\nt3 <- t1 %>%\n        mutate(class = \"Pass.\\nCrew\") %>%\n        group_by(class, new_sex, survived) %>%\n        summarize(n_sgnd = sum(n_sgnd))\n\n`summarise()` has grouped output by 'class', 'new_sex'. You can override using\nthe `.groups` argument.\n\n# Combined cleaned plotting dataset\nttnc_cln <- t1 %>%\n              bind_rows(t2) %>%\n              bind_rows(t3) %>%\n              mutate(.data = .,\n                            class = as.factor(class),\n                            new_sex = as.factor(new_sex),\n                            survived = as.factor(survived))\n\n# Display first 8 rows in a nice centered table\nttnc_cln %>%\n  slice(.data = ., 1:8) %>%\n  kable(x = ., align = 'c')\n\n\n\nclass\nnew_sex\nsurvived\nn_sgnd\n\n\n\n3rd\nChild\nNo\n-35\n\n\n3rd\nChild\nNo\n-17\n\n\n1st\nMale\nNo\n-118\n\n\n2nd\nMale\nNo\n-154\n\n\n3rd\nMale\nNo\n-387\n\n\nCrew\nMale\nNo\n-670\n\n\n1st\nFemale\nNo\n-4\n\n\n2nd\nFemale\nNo\n-13\n\n\n\n\n\nLooks nice. As you can see, the data cleaning was done in stages where 3 datasets t1, t2, t3 were built up. Essentially by staring at the plot it is clear that plots are split by class i.e.¬†\\(1^{st}\\) Class, \\(2^{nd}\\) Class etc. This is the cleaned t1 data frame. However there are aggregate versions of these classes at combined Passenger level and Passenger and Crew level which are the t2 and t3 tibbles respectively. Finally we concatenate them together into ttnc_cln and ensure our categorical variables are cast as factors.\nNext step - plotting!"
  },
  {
    "objectID": "posts/2019-07-21-shrotriya2019reprtitanic/shrotriya2019reprtitanic.html#plotting-the-data",
    "href": "posts/2019-07-21-shrotriya2019reprtitanic/shrotriya2019reprtitanic.html#plotting-the-data",
    "title": "Reproducibility Challenge: Titanic Survivors Plot",
    "section": "Plotting the Data",
    "text": "Plotting the Data\nThe main chart object is a barplot by sex and adult status and faceted by passenger class i.e.¬†first class, second class etc. Great, let‚Äôs do it!\n\nout_plot <- ttnc_cln %>%\n              ggplot(data = .,\n                              aes(x = new_sex, y = n_sgnd, fill = survived)) +\n              geom_bar(stat = \"identity\") +\n              facet_wrap(~ class, ncol = 1,\n                                  strip.position = \"right\",\n                                  scales = \"free_y\") +\n              coord_flip() +\n              scale_fill_manual(values=c(\"#3C4144\", \"#D2D3D1\")) +\n              theme_bw() +\n              theme(panel.background = element_rect(fill = \"#969898\"),\n                             panel.grid.major = element_blank(),\n                             panel.grid.minor = element_blank(),\n                             axis.title.x = element_blank(),\n                             axis.title.y = element_blank(),\n                             strip.text.y = element_text(angle = 360),\n                             legend.position = \"none\") +\n              scale_y_continuous(breaks=seq(-1500,600,150)) +\n              labs(title = 'The LOSS of the \"TITANIC\"',\n                            subtitle = glue::glue(\"The Results Analyzed and Shown\",\n                                                  'in a special \"Sphere\" Diagram',\n                                                  .sep = \" \"),\n                            caption = glue::glue(\"Note: The Black color indicates\",\n                                                 \"Passengers and Crew NOT SAVED.\",\n                                                 \"The White color indicates SAVED.\",\n                                                  .sep = \" \"))\n\nout_plot"
  },
  {
    "objectID": "posts/2019-07-21-shrotriya2019reprtitanic/shrotriya2019reprtitanic.html#conclusion",
    "href": "posts/2019-07-21-shrotriya2019reprtitanic/shrotriya2019reprtitanic.html#conclusion",
    "title": "Reproducibility Challenge: Titanic Survivors Plot",
    "section": "Conclusion",
    "text": "Conclusion\n\nOverall looks like the plot was able to be reproduced to a decent level of accuracy\nTo get the colors to be close to the plot, I simply opened the article online and used the Colorzilla for Chrome addin to select the color manually. This is a really nice tool to use for reproducing colors viewed through a browser\nI don‚Äôt quite like that the non-survivors here are shown on a negative scale, but this was the quick hack I could perform to get bars flipped for non-survivors vs.¬†survivors\n\nSummary: Overall this was a really fun challenge and I learned a lot about old-school data visualization using the glorius modern tidyverse ecosystem we have at our fingertips. Will do a similar reproducibility challenge again for sure ‚úåÔ∏è. Have fun playing around with the above and please post in the comments any questions/feedback you may have üëç."
  },
  {
    "objectID": "posts/2019-07-21-shrotriya2019reprtitanic/shrotriya2019reprtitanic.html#acknowledgments",
    "href": "posts/2019-07-21-shrotriya2019reprtitanic/shrotriya2019reprtitanic.html#acknowledgments",
    "title": "Reproducibility Challenge: Titanic Survivors Plot",
    "section": "Acknowledgments",
    "text": "Acknowledgments\nI‚Äôd like to thank Salil Shrotriya for creating the preview image for this post. The hex sticker png files were sourced from here."
  },
  {
    "objectID": "posts/2019-07-30-shrotriya2019july19roundup/index.html",
    "href": "posts/2019-07-30-shrotriya2019july19roundup/index.html",
    "title": "Shamindra‚Äôs July 2019 Roundup",
    "section": "",
    "text": "This is a new feature I‚Äôm going to experiment with, namely documenting anything interesting I come across (articles, lectures, books, papers etc.) and any activities I get up to. This is more for my personal benefit but may also help others. Let‚Äôs see how this experiment goes!"
  },
  {
    "objectID": "posts/2019-07-30-shrotriya2019july19roundup/index.html#interesting-articles",
    "href": "posts/2019-07-30-shrotriya2019july19roundup/index.html#interesting-articles",
    "title": "Shamindra‚Äôs July 2019 Roundup",
    "section": "Interesting Articles",
    "text": "Interesting Articles\n\nCame across this exhaustive BibTex example file which will be a really handy reference going forward for \\(\\LaTeX\\) documents\n\nThis Pimp my RMD: a few tips for R Markdown document is a very good site to help deal with really slick features of editing Rmd documents.\n\nOne nice feature I noticed was to use HTML to center an image"
  },
  {
    "objectID": "posts/2019-07-30-shrotriya2019july19roundup/index.html#interesting-books",
    "href": "posts/2019-07-30-shrotriya2019july19roundup/index.html#interesting-books",
    "title": "Shamindra‚Äôs July 2019 Roundup",
    "section": "Interesting Books",
    "text": "Interesting Books\nNon-fiction\n\nContinued reading this fantastic book (Steele 2004) called the Art of Mathematical inequalities by Prof.¬†Michael Steele. This book is simply amazing in that Prof.¬†Steele walks through deriving mathematical inequalities as if you were having a casual chat together using a whiteboard. I‚Äôve been working through through the problems in detail and they are a great challenge! I‚Äôll blog more about this as I finish the book in the August 2019 roundup.\n\nNote: the text contains full solutions making it ideal for self-study (but I refuse to peek for now)\nFiction\n\nRead Celeste Ng‚Äôs Everything I Never Told You. Very nicely written debut novel by Ng, though quite dark and brooding in tone. Would not recommend as a pick me up but certainly would for a nice American-Asian character study set in the 1970s."
  },
  {
    "objectID": "posts/2019-07-30-shrotriya2019july19roundup/index.html#interesting-papers",
    "href": "posts/2019-07-30-shrotriya2019july19roundup/index.html#interesting-papers",
    "title": "Shamindra‚Äôs July 2019 Roundup",
    "section": "Interesting Papers",
    "text": "Interesting Papers\n\nParticularly enjoyed reading this paper on the mathematical description of the carbon cycle (Rothman 2014). Really useful to get a good idea of the simple but powerful use of simple stochastic differential equations used to model climate change processes at various global scales."
  },
  {
    "objectID": "posts/2019-07-30-shrotriya2019july19roundup/index.html#personal-blogging",
    "href": "posts/2019-07-30-shrotriya2019july19roundup/index.html#personal-blogging",
    "title": "Shamindra‚Äôs July 2019 Roundup",
    "section": "Personal Blogging",
    "text": "Personal Blogging\nBesides this post üòÑ the main things I got up to on the personal blogging front were:\n\nSetting up this very blog, with a detailed step-by-step guide on the fun setup process with the RStudio distill package and also Netlify and Google Domains\n\nWrote a fun blogpost on solving a couple of quick text-based tasks using the tidyverse including generating Oxford Comma triples and also Generating numbered BibTeX entries"
  },
  {
    "objectID": "posts/2019-07-30-shrotriya2019july19roundup/index.html#concluding-thoughts",
    "href": "posts/2019-07-30-shrotriya2019july19roundup/index.html#concluding-thoughts",
    "title": "Shamindra‚Äôs July 2019 Roundup",
    "section": "Concluding Thoughts",
    "text": "Concluding Thoughts\nOverall July 2019 was a somewhat productive summer month. Though things are never quite as productive as I like them to be in graduate school, but always got to keep trying.\nI liked documenting this personal July 2019 roundup. Normally I‚Äôm not the type to share much about my personal life, but I thought documenting what I get up to gives me more stake in the respective activities and forces me to commit to them enthusiastically. I also like sharing cool stuff that I come across with friends, so dual benefit.\nI think I‚Äôll keep these monthly roundups going for a while. Let‚Äôs see how this experiment goes when semester starts üòÑ.\nPlease post in the comments any questions/feedback you may have or anything interesting resources you came across in July 2019 üëç."
  },
  {
    "objectID": "posts/2019-07-31-shrotriya2019distillpt2/index.html",
    "href": "posts/2019-07-31-shrotriya2019distillpt2/index.html",
    "title": "Upgrading Distill Blog Settings",
    "section": "",
    "text": "This is a meta blogpost and a second-part in a series to describe how I setup this personal academic blog using the amazing distill package by the RStudio team.\nThe first part of this meta blogpost series can be found here, where I detailed the steps to setup this blog using Netlify and Google Domains. If you haven‚Äôt setup a distill themed blog then you are encouraged to check it out before reading this post.\nFortunately distill comes with easy to configure settings as well see below. I‚Äôve only implemented some of the options available. I should note that the RStudio distill team has already created an excellent distill blog creation tutorial which I thoroughly used and highly recommend to new users to check out.\n\nAdmittedly this blogpost is verbose, but hopefully the details help new users of the distill blogging package.\n\nWith that said, here are some key upgrades I made to this blog."
  },
  {
    "objectID": "posts/2019-07-31-shrotriya2019distillpt2/index.html#step-1-setup-disqus-comments",
    "href": "posts/2019-07-31-shrotriya2019distillpt2/index.html#step-1-setup-disqus-comments",
    "title": "Upgrading Distill Blog Settings",
    "section": "Step 1: Setup Disqus comments",
    "text": "Step 1: Setup Disqus comments\nI really wanted to setup some comments system for each blogpost. This way I can learn new tips from readers and find out how to improve posts going forward. I will go with the recommended Disqus comments option from the distill blog. I simply created a Disqus account and selected Get Started. I then clicked the following button to Install Disqus on my site.\n\n\n\nGetting Started with Disqus\n\n\nI was then presented with the following Disqus site configuration menu. I entered https:://www.shamindras.com/ for my Website Name and manually set my Disqus shortname to be shamindras-distill to be easier to remember and specific to this site, in case I make more websites later on. This Disqus shortname is important to note down (üñä) as we‚Äôll see shortly.\n\n\n\nSetup Disqus shortname\n\n\nAfter clicking Create Site in the previous menu I proceeded to select the free plan option by subscribing to the Basic, Free, Ads Supported comments option as seen below:\n\nAs a student got to always know when to get a freebie üòÑ\n\n\n\n\nSelect Basic (Free, Ads supported) mode\n\n\nIn terms of implementing Disqus on my site, I clicked on the following button to install Disqus on my site manually:\n\n\n\nManual installation of Disqus\n\n\nBefore finishing the manual installation of Disqus I ensured that I set the following configuration options. I particularly like setting an opiononated comments policy and selected the Grist Comment Policy:\n\n\n\nDisqus Configuration Settings\n\n\nFinally to ensure that the implementation is completed I added the following line to the _site.yml post using the Disqus shortname set earlier i.e. shamindras-distill and ensuring hidden: true so that the comments are not expanded by default:\n\nNote: You can see my _site.yml with these settings here\n\n\ncollections:\n  posts:\n    disqus:\n      shortname: shamindras-distill\n      hidden: true\n\nWe now see the following comments option at the bottom of every post:\n\n\n\nDistill Disqus Comments Selection\n\n\nYou can read more about setting up comments from the official distill blog here"
  },
  {
    "objectID": "posts/2019-07-31-shrotriya2019distillpt2/index.html#step-2-setup-google-analytics-tracking",
    "href": "posts/2019-07-31-shrotriya2019distillpt2/index.html#step-2-setup-google-analytics-tracking",
    "title": "Upgrading Distill Blog Settings",
    "section": "Step 2: Setup Google Analytics tracking",
    "text": "Step 2: Setup Google Analytics tracking\nI also wanted to setup basic user viewing tracking for my site. Fortunately distill can be easily configured to work with Google Analytics. In order to set this up I simply created an account for Google Analytics (using my personal gmail account). I then logged in and selected the option to track my website as follows:\n\n\n\nGoogle Analytics Settings\n\n\nNote that I specified the Website Name field to be shamindras-distill. This is indeed the same as the Disqus shortname from earlier but did not have to be. I just did it for consistency and easy reference. I was then given a Google Analytics token and concluded this setup by adding the token to the _site.yml file as follows:\n\nNote: You can see my _site.yml with these settings here\n\n\ngoogle_analytics: \"UA-145015693-1\"\n\nYou can read more about setting up Google Analytics from the official distill blog here"
  },
  {
    "objectID": "posts/2019-07-31-shrotriya2019distillpt2/index.html#step-3-add-netlify-status-badge",
    "href": "posts/2019-07-31-shrotriya2019distillpt2/index.html#step-3-add-netlify-status-badge",
    "title": "Upgrading Distill Blog Settings",
    "section": "Step 3: Add Netlify Status Badge",
    "text": "Step 3: Add Netlify Status Badge\nSince Netlify is the web hosting platform for my site (see setup details here). I just logged into my Netlify account and went to my Site Details and obtained the following code from the Status Badges option.\n\n\n\nNetlify Badge Code\n\n\nI copy-pasted the above code in at the top of my site README.md file. This let‚Äôs me quickly know whether my website is up and running as expected by simply checking out my github page.\n\nNote: You can see my README.md with these settings here"
  },
  {
    "objectID": "posts/2019-07-31-shrotriya2019distillpt2/index.html#step-4-add-blog-post-sharing-options",
    "href": "posts/2019-07-31-shrotriya2019distillpt2/index.html#step-4-add-blog-post-sharing-options",
    "title": "Upgrading Distill Blog Settings",
    "section": "Step 4: Add blog post sharing options",
    "text": "Step 4: Add blog post sharing options\nIt is easy to configure distill to allow for easy sharing of posts using a variety of social media platforms. I allow for twitter, linkedin, pinterest, and facebook. I did this by simply adding the following line in the _site.yml file:\n\ncollections:\n  posts:\n    share: [twitter, linkedin, pinterest, facebook]\n\nNow the following sharing options appear at the bottom of every post:\n\n\n\nDistill Sharing Options\n\n\nI also added in the following lines to _site.yml to ensure that twitter cards are correctly generated when posts are shared on twitter:\n\nNote: You can see my _site.yml with these settings here\n\n\ntwitter:\n  site: \"@shamindraas\"\n  creator: \"@shamindraas\""
  },
  {
    "objectID": "posts/2019-07-31-shrotriya2019distillpt2/index.html#step-5-add-correctionschange-tracking-and-rss-feed",
    "href": "posts/2019-07-31-shrotriya2019distillpt2/index.html#step-5-add-correctionschange-tracking-and-rss-feed",
    "title": "Upgrading Distill Blog Settings",
    "section": "Step 5: Add Corrections/Change Tracking and RSS feed",
    "text": "Step 5: Add Corrections/Change Tracking and RSS feed\nI frequently make edits to blogposts and intend to do so going forward. Fortunately distill makes it easy track changes/corrections made to blogposts. I did this by simply adding the site repo url to the _site.yml as follows:\n\nrepository_url: https://github.com/shamindras/ss_personal_distill_blog\n\nNow the following appears at the bottom of all blogposts:\n\n\n\nChanges and Corrections Tracking\n\n\nSo users can easily track changes or file any concerns as issues, though hopefully the Disqus comment feature makes this easier for everyone.\nFinally it is easy to add an RSS feed for the blog by simply adding the following to _site.yml:\n\nbase_url: https://www.shamindras.com/\nnavbar:\n  left:\n    - icon: fa fa-rss\n      href: index.xml\n\n\nNote: You can see my _site.yml with these settings here\n\nThe critical elements are adding in the base_url fields and adding in fa fa-rss which is derived from the index.xml file. The index.xml file is automatically generated from the index.Rmd when you render the distill blog using the usual command:\n\nrmarkdown::render_site(here::here())"
  },
  {
    "objectID": "posts/2019-07-31-shrotriya2019distillpt2/index.html#next-steps",
    "href": "posts/2019-07-31-shrotriya2019distillpt2/index.html#next-steps",
    "title": "Upgrading Distill Blog Settings",
    "section": "Next Steps",
    "text": "Next Steps\nIn terms of core distill blog settings, these are the main options that I‚Äôm happy to implement for now. For me the next steps are more about customizing my own blog workflow. This will involve setting up utilities to automatically:\n\nWrap Rmd files to 80 characters for consistency\nQuickly delete unused files e.g.¬†DS_Store files on mac\nClear knitr cache for all posts and thoroughly re-render the site\n\nI expect to do this using a combination of R functions/Makefile workflow, but do stay tuned!"
  },
  {
    "objectID": "posts/2019-07-31-shrotriya2019distillpt2/index.html#concluding-thoughts",
    "href": "posts/2019-07-31-shrotriya2019distillpt2/index.html#concluding-thoughts",
    "title": "Upgrading Distill Blog Settings",
    "section": "Concluding Thoughts",
    "text": "Concluding Thoughts\nAs it can be seen it is quite easy to customize distill for commonly required features. Really great work by the RStudio team in making such customizations so user-friendly üëç."
  },
  {
    "objectID": "posts/2019-07-21-shrotriya2019reprtitanic/index.html",
    "href": "posts/2019-07-21-shrotriya2019reprtitanic/index.html",
    "title": "Reproducibility Challenge: Titanic Survivors Plot",
    "section": "",
    "text": "In the February 2019 issue of Significance Magazine notably featured a story of the titanic disaster (Friendly, Symanzik, and Onder 2019) and visualization of key survival statistics. As a fan of R and data visualization I enjoyed this article and recommended it to anyone with similar interests. Although the subject is rather tragic, by reading the article I did get a better appreciation of how the information of the crash survivorship was conveyed to the general public through data visualization.\n\n\ncover"
  },
  {
    "objectID": "posts/2019-07-21-shrotriya2019reprtitanic/index.html#reproducibility-challenge",
    "href": "posts/2019-07-21-shrotriya2019reprtitanic/index.html#reproducibility-challenge",
    "title": "Reproducibility Challenge: Titanic Survivors Plot",
    "section": "Reproducibility Challenge",
    "text": "Reproducibility Challenge\nOf particular note in the article was the following data visualization poster printed shortly after the tragedy:\n\n\nG.Bron‚Äôs chart of ‚ÄúThe Loss of the ‚ÄòTitanic‚Äô‚Äù, from The Sphere, 4 May 1912\n\n\nI found this to be a very cool data visualization of the survivorship by class, gender, and adulthood. As a statistics graduate student, I care a lot about reproducibility of results not only as a basic check, but to really appreciate the results and more importantly any implicit assumptions behind the results. So this led to the following goal and effectively this blogpost:\nNote: Replicability is better, but reproducibility is a good start and often a more practically feasible undertaking\nGoal: Given the same Titanic survivors data could we recreate a similar looking chart using R and specifically the tidyverse set of tools?"
  },
  {
    "objectID": "posts/2019-07-21-shrotriya2019reprtitanic/index.html#collecting-and-cleaning-the-data",
    "href": "posts/2019-07-21-shrotriya2019reprtitanic/index.html#collecting-and-cleaning-the-data",
    "title": "Reproducibility Challenge: Titanic Survivors Plot",
    "section": "Collecting and cleaning the data",
    "text": "Collecting and cleaning the data\nFirst let‚Äôs begin by loading our required data cleaning and plotting packages. First we will load the required libraries needed for the analysis.\n\n\n\nIn the article the authors cite several resources for collecting the data for this task. Per the article we note that the data is already pre-baked into R and located in datasets::Titanic when R loads, which is convenient üòé.\nWe can source the data and start cleaning it for our exploration, using the handy clean_names function for column name cleaning and converting various categorical variables (age, sex, survivorship, and passenger class) to factors for easy plotting later.\n\n# Basic cleaning of names and filtering out non-zero counts\nt1 <- datasets::Titanic %>%\n        as_tibble() %>%\n        clean_names(dat = .) %>%\n        filter(.data = ., n != 0) %>%\n        mutate(.data = .,\n                      new_sex = ifelse(age == \"Child\", age, sex),\n                      n_sgnd = ifelse(survived == \"No\", -1*n, n)) %>%\n        select(class, new_sex, survived, n_sgnd)\n\n# Passenger (non-crew) level aggregation\nt2 <- t1 %>%\n        filter(class != \"Crew\") %>%\n        mutate(class = \"Pass.\") %>%\n        group_by(class, new_sex, survived) %>%\n        summarize(n_sgnd = sum(n_sgnd))\n\n`summarise()` has grouped output by 'class', 'new_sex'. You can override using\nthe `.groups` argument.\n\n# Crew (non-passenger) level aggregation\nt3 <- t1 %>%\n        mutate(class = \"Pass.\\nCrew\") %>%\n        group_by(class, new_sex, survived) %>%\n        summarize(n_sgnd = sum(n_sgnd))\n\n`summarise()` has grouped output by 'class', 'new_sex'. You can override using\nthe `.groups` argument.\n\n# Combined cleaned plotting dataset\nttnc_cln <- t1 %>%\n              bind_rows(t2) %>%\n              bind_rows(t3) %>%\n              mutate(.data = .,\n                            class = as.factor(class),\n                            new_sex = as.factor(new_sex),\n                            survived = as.factor(survived))\n\n# Display first 8 rows in a nice centered table\nttnc_cln %>%\n  slice(.data = ., 1:8) %>%\n  kable(x = ., align = 'c')\n\n\n\nclass\nnew_sex\nsurvived\nn_sgnd\n\n\n\n3rd\nChild\nNo\n-35\n\n\n3rd\nChild\nNo\n-17\n\n\n1st\nMale\nNo\n-118\n\n\n2nd\nMale\nNo\n-154\n\n\n3rd\nMale\nNo\n-387\n\n\nCrew\nMale\nNo\n-670\n\n\n1st\nFemale\nNo\n-4\n\n\n2nd\nFemale\nNo\n-13\n\n\n\n\n\nLooks nice. As you can see, the data cleaning was done in stages where 3 datasets t1, t2, t3 were built up. Essentially by staring at the plot it is clear that plots are split by class i.e.¬†\\(1^{st}\\) Class, \\(2^{nd}\\) Class etc. This is the cleaned t1 data frame. However there are aggregate versions of these classes at combined Passenger level and Passenger and Crew level which are the t2 and t3 tibbles respectively. Finally we concatenate them together into ttnc_cln and ensure our categorical variables are cast as factors.\nNext step - plotting!"
  },
  {
    "objectID": "posts/2019-07-21-shrotriya2019reprtitanic/index.html#plotting-the-data",
    "href": "posts/2019-07-21-shrotriya2019reprtitanic/index.html#plotting-the-data",
    "title": "Reproducibility Challenge: Titanic Survivors Plot",
    "section": "Plotting the Data",
    "text": "Plotting the Data\nThe main chart object is a barplot by sex and adult status and faceted by passenger class i.e.¬†first class, second class etc. Great, let‚Äôs do it!\n\nout_plot <- ttnc_cln %>%\n              ggplot(data = .,\n                              aes(x = new_sex, y = n_sgnd, fill = survived)) +\n              geom_bar(stat = \"identity\") +\n              facet_wrap(~ class, ncol = 1,\n                                  strip.position = \"right\",\n                                  scales = \"free_y\") +\n              coord_flip() +\n              scale_fill_manual(values=c(\"#3C4144\", \"#D2D3D1\")) +\n              theme_bw() +\n              theme(panel.background = element_rect(fill = \"#969898\"),\n                             panel.grid.major = element_blank(),\n                             panel.grid.minor = element_blank(),\n                             axis.title.x = element_blank(),\n                             axis.title.y = element_blank(),\n                             strip.text.y = element_text(angle = 360),\n                             legend.position = \"none\") +\n              scale_y_continuous(breaks=seq(-1500,600,150)) +\n              labs(title = 'The LOSS of the \"TITANIC\"',\n                            subtitle = glue::glue(\"The Results Analyzed and Shown\",\n                                                  'in a special \"Sphere\" Diagram',\n                                                  .sep = \" \"),\n                            caption = glue::glue(\"Note: The Black color indicates\",\n                                                 \"Passengers and Crew NOT SAVED.\",\n                                                 \"The White color indicates SAVED.\",\n                                                  .sep = \" \"))\n\nout_plot"
  },
  {
    "objectID": "posts/2019-07-21-shrotriya2019reprtitanic/index.html#conclusion",
    "href": "posts/2019-07-21-shrotriya2019reprtitanic/index.html#conclusion",
    "title": "Reproducibility Challenge: Titanic Survivors Plot",
    "section": "Conclusion",
    "text": "Conclusion\n\nOverall looks like the plot was able to be reproduced to a decent level of accuracy\nTo get the colors to be close to the plot, I simply opened the article online and used the Colorzilla for Chrome addin to select the color manually. This is a really nice tool to use for reproducing colors viewed through a browser\nI don‚Äôt quite like that the non-survivors here are shown on a negative scale, but this was the quick hack I could perform to get bars flipped for non-survivors vs.¬†survivors\n\nSummary: Overall this was a really fun challenge and I learned a lot about old-school data visualization using the glorius modern tidyverse ecosystem we have at our fingertips. Will do a similar reproducibility challenge again for sure ‚úåÔ∏è. Have fun playing around with the above and please post in the comments any questions/feedback you may have üëç."
  },
  {
    "objectID": "posts/2019-07-21-shrotriya2019reprtitanic/index.html#acknowledgments",
    "href": "posts/2019-07-21-shrotriya2019reprtitanic/index.html#acknowledgments",
    "title": "Reproducibility Challenge: Titanic Survivors Plot",
    "section": "Acknowledgments",
    "text": "Acknowledgments\nI‚Äôd like to thank Salil Shrotriya for creating the preview image for this post. The hex sticker png files were sourced from here."
  },
  {
    "objectID": "posts/2019-08-21-shrotriya2019tidyfunpt2/index.html",
    "href": "posts/2019-08-21-shrotriya2019tidyfunpt2/index.html",
    "title": "Tidyverse Fun - Part 2",
    "section": "",
    "text": "In a custom \\(\\LaTeX\\) macro file I needed to generate several sequential \\(\\LaTeX\\) newcommand entries of the form:\n\\newcommand{\\bfa}{\\mathbf{a}}\n\\newcommand{\\bfA}{\\mathbf{A}}\nWhere using $\\bfa$ produces \\(\\mathbf{a}\\) and using $\\bfA$ produces \\(\\mathbf{A}\\) i.e the lowecase/uppercase mathbf commands respectively.\nSpecifically I needed to construct 52 such combined sequential entries for both lowercase/uppercase letter versions of these newcommand \\(\\LaTeX\\) macros. Rather than do this manually, I realized that this would be another fun scripting exercise with using the tidyverse packages glue, purrr, and stringr similar to this similar previous post here.\nGoal: Create 52 such lowercase/uppercase newcommand entries and print to the console to directly-copy paste to my \\(\\LaTeX\\) macros file.\n\n\n\nFirst step is to write a function that takes as an input the following:\n\na single letter (case-sensitive) e.g.¬†\"a\"\nthe macro shortcut command prefix you prefer e.g \"bf\" (for bold font in case you were wondering!)\nthe specific \\(\\LaTeX\\) command that we are creating a macro shortcut for i.e.¬†\"mathbf\" in this case\n\nThe function then outputs a single newcommand entry for that lecture i.e \\newcommand{\\bfa}{\\mathbf{a}} in this case. Let‚Äôs do it!\n\n# Load required libraries\nlibrary(tidyverse)\nlibrary(glue)\n\n# Create LaTeX macro newcommand\nget_lec_newcmd <- function(inp_letr, mac_type, mac_ref){\n    out_str <- glue('\\\\newcommand{\\\\<mac_type><inp_letr>}{\\\\<mac_ref>{<inp_letr>}}',\n                    .open = \"<\", .close = \">\")\n    return(out_str)\n}\n\nLet‚Äôs just test this out quickly:\n\nc(\"a\", \"A\") %>%\n  map_chr(.x = ., .f = ~get_lec_newcmd(inp_letr = .x,\n                                       mac_type = \"bf\",\n                                       mac_ref = \"mathbf\")) %>%\n  cat(., sep = \"\\n\")\n\n\\newcommand{\\bfa}{\\mathbf{a}}\n\\newcommand{\\bfA}{\\mathbf{A}}\n\n\nGreat - looks like it is working as required!\nNote that we can easily generate other \\(\\LaTeX\\) macros like follows\n\nc(\"a\", \"A\") %>%\n  map_chr(.x = ., .f = ~get_lec_newcmd(inp_letr = .x,\n                                       mac_type = \"mc\",\n                                       mac_ref = \"mathcal\")) %>%\n  cat(., sep = \"\\n\")\n\n\\newcommand{\\mca}{\\mathcal{a}}\n\\newcommand{\\mcA}{\\mathcal{A}}\n\n\nWhich generates the corresponding mathcal macros for \\(\\mathcal{a}\\) and \\(\\mathcal{A}\\) respectively.\nSo finally we can generate all 52 letter macros at time by simply replacing c(\"a\", \"A\") with c(letters, LETTERS) which uses the input lowercase/uppercase letters/LETTERS vectors in base R:\n\n\n\n Full newcommand Demo Output \n\n\n\\newcommand{\\bfa}{\\mathbf{a}}\n\\newcommand{\\bfb}{\\mathbf{b}}\n\\newcommand{\\bfc}{\\mathbf{c}}\n\\newcommand{\\bfd}{\\mathbf{d}}\n\\newcommand{\\bfe}{\\mathbf{e}}\n\\newcommand{\\bff}{\\mathbf{f}}\n\\newcommand{\\bfg}{\\mathbf{g}}\n\\newcommand{\\bfh}{\\mathbf{h}}\n\\newcommand{\\bfi}{\\mathbf{i}}\n\\newcommand{\\bfj}{\\mathbf{j}}\n\\newcommand{\\bfk}{\\mathbf{k}}\n\\newcommand{\\bfl}{\\mathbf{l}}\n\\newcommand{\\bfm}{\\mathbf{m}}\n\\newcommand{\\bfn}{\\mathbf{n}}\n\\newcommand{\\bfo}{\\mathbf{o}}\n\\newcommand{\\bfp}{\\mathbf{p}}\n\\newcommand{\\bfq}{\\mathbf{q}}\n\\newcommand{\\bfr}{\\mathbf{r}}\n\\newcommand{\\bfs}{\\mathbf{s}}\n\\newcommand{\\bft}{\\mathbf{t}}\n\\newcommand{\\bfu}{\\mathbf{u}}\n\\newcommand{\\bfv}{\\mathbf{v}}\n\\newcommand{\\bfw}{\\mathbf{w}}\n\\newcommand{\\bfx}{\\mathbf{x}}\n\\newcommand{\\bfy}{\\mathbf{y}}\n\\newcommand{\\bfz}{\\mathbf{z}}\n\\newcommand{\\bfA}{\\mathbf{A}}\n\\newcommand{\\bfB}{\\mathbf{B}}\n\\newcommand{\\bfC}{\\mathbf{C}}\n\\newcommand{\\bfD}{\\mathbf{D}}\n\\newcommand{\\bfE}{\\mathbf{E}}\n\\newcommand{\\bfF}{\\mathbf{F}}\n\\newcommand{\\bfG}{\\mathbf{G}}\n\\newcommand{\\bfH}{\\mathbf{H}}\n\\newcommand{\\bfI}{\\mathbf{I}}\n\\newcommand{\\bfJ}{\\mathbf{J}}\n\\newcommand{\\bfK}{\\mathbf{K}}\n\\newcommand{\\bfL}{\\mathbf{L}}\n\\newcommand{\\bfM}{\\mathbf{M}}\n\\newcommand{\\bfN}{\\mathbf{N}}\n\\newcommand{\\bfO}{\\mathbf{O}}\n\\newcommand{\\bfP}{\\mathbf{P}}\n\\newcommand{\\bfQ}{\\mathbf{Q}}\n\\newcommand{\\bfR}{\\mathbf{R}}\n\\newcommand{\\bfS}{\\mathbf{S}}\n\\newcommand{\\bfT}{\\mathbf{T}}\n\\newcommand{\\bfU}{\\mathbf{U}}\n\\newcommand{\\bfV}{\\mathbf{V}}\n\\newcommand{\\bfW}{\\mathbf{W}}\n\\newcommand{\\bfX}{\\mathbf{X}}\n\\newcommand{\\bfY}{\\mathbf{Y}}\n\\newcommand{\\bfZ}{\\mathbf{Z}}\n\n\n\nHope you have fun using this to quickly generate your \\(\\LaTeX\\) newcommand macros ‚úåÔ∏è."
  },
  {
    "objectID": "posts/2019-09-01-shrotriya2019august19roundup/index.html",
    "href": "posts/2019-09-01-shrotriya2019august19roundup/index.html",
    "title": "Shamindra‚Äôs August 2019 Roundup",
    "section": "",
    "text": "Welcome to the August 2019 roundup! Similar to last time I‚Äôm going to experiment with, namely documenting anything interesting I come across (articles, lectures, books, papers etc.) and any activities I get up to. This is more for my personal benefit but may also help others."
  },
  {
    "objectID": "posts/2019-09-01-shrotriya2019august19roundup/index.html#interesting-articles",
    "href": "posts/2019-09-01-shrotriya2019august19roundup/index.html#interesting-articles",
    "title": "Shamindra‚Äôs August 2019 Roundup",
    "section": "Interesting Articles",
    "text": "Interesting Articles\n\nCame across this exhaustive BibTeX example file which will be a really handy reference going forward for \\(\\LaTeX\\) documents\nThe document is written by the Oren Patashnik, the co-creator of BibTeX (üòÆ) and the co-author of the great book (Graham, Knuth, and Patashnik 1994)"
  },
  {
    "objectID": "posts/2019-09-01-shrotriya2019august19roundup/index.html#interesting-books",
    "href": "posts/2019-09-01-shrotriya2019august19roundup/index.html#interesting-books",
    "title": "Shamindra‚Äôs August 2019 Roundup",
    "section": "Interesting Books",
    "text": "Interesting Books\nFiction\n\nStarted reading this fantastic book (Granville, Granville, and Lewis 2019) called the Prime Suspects by Andrew Granville, Jennifer Granville, and Robert J. Lewis (illustrator). Here is a youtube trailer for the book to get you excited!\n\n\n\nPrime Suspects cover\n\n\nKey Takeaways\n\nThis is essentially an introduction to analytic number theory disguised as a fast-moving graphic novel murder mystery\nFor any mathematics fans (who isn‚Äôt though?) there are lots of funny easter eggs to be found in the frame backgrounds\nThis a very unique exposition on number theory, a subject in which I have negligible knowledge (like most subjects)\nThe pedagogy is gentle and yet exciting emphasizing not just mathematics but the importance of communication of mathematical ideas to the wider public i.e.¬†a meta novel if you like\nI hope to see more books in this mathematical graphic novel genre. The last one I read (and know of) is Logicomix (Doxiadis et al. 2009) which I highly recommend as well for anyone wishing to venture into the mysteries of infinity!"
  },
  {
    "objectID": "posts/2019-09-01-shrotriya2019august19roundup/index.html#interesting-interviews",
    "href": "posts/2019-09-01-shrotriya2019august19roundup/index.html#interesting-interviews",
    "title": "Shamindra‚Äôs August 2019 Roundup",
    "section": "Interesting Interviews",
    "text": "Interesting Interviews\n\nReally enjoyed this interview with Prof.¬†Noga Alon a leading mathematician specializing in combinatorics, graph theory etc. Fantastic insights into the life of a (leading) theoretical researcher and certainly someone for me to look up to and learn from. I enjoyed the fact that it was so brief but dense as I normally don‚Äôt have much time for podcasts. I may check out a few more scientific based interviews from this Career Yoga podcast going forward.\n\nNote: This interview was co-conducted Ms.¬†Narkis Alon, the daughter of Prof. Alon which led to a really personal dynamic!\nKey Takeaways\n\nThis 20min interview is really part of a podcast on careers, and the focus here being the lessons/insights learned from a very successful career in theoretical mathematical research from Prof.¬†Alon\nProf.¬†Alon appears to be extremely organized in all aspects of life, including packing for trips. Was asked specifically not to prepare for this interview üòÑ\nI‚Äôve paraphrased my summaries below, any transcription errors are mine. Please listen to the original interview.\nQuestion: What does it mean to be a mathematician?\n\n\nTo mostly think about mathematical problems, there are many mathematical problems that have rich history, many are interesting in their own sense. It means to ask the right questions, think about interesting questions and tell the difference between what is beautiful and what is not beautiful\n\n\nQuestion: What does your day look like?\n\n\nMany procedural things - teaching, meeting graduate students, reading mathematical papers.\n\n\nPart of the time I‚Äôm just thinking! Sometimes with other people over chalkboard/whiteboard, looking at a piece of paper on the table i.e.¬†trying to do some computations that are relevant, thinking of relationships to the problem. Finding problems that are similar enough.\n\n\nQuestion: It is so difficult to grasp the idea of just thinking! Most of the careers are based on the idea of responding to things. Often when visiting you in Princeton it seems you are in a room staring in the air, in another room people another mathematician is staring in the air, it seems like you are not doing anything!\n\n\nRight, and indeed in much of time you are not doing anything. Most of the time you are failing and you need to get used to to it Part of the satisfaction is this process is to think about something for a very long time without having an idea. Sometimes you solve something related\n\n\nQuestion: Do you sometimes try to initiate situations that will inspire you to solve problems\n\n\nYou go to conferences, talk to people, read papers etc. Many times you just need to be in a different state of mind e.g.¬†if you forget someones name, just thinking about it does not always make you remember, just need to try something else at times. This may explain why you see people staring in the air! Sometimes you can go and take walks.\n\n\nQuestion: When did you know you wanted to be a mathematician?\n\n\nAs a child, before I was 10 years old I knew I was interested in mathematical puzzles. I was good at it and interested in mathematics but didn‚Äôt really know what it involved. I always liked that it is objective. I was able to explain a solution to an adult at a party on the puzzle of the Eurovision song contest. The power of convincing someone is really powerful.\n\n\nQuestion: Was the long list of awards you aimed for?\n\n\nNo, it‚Äôs nice to get such prizes but never done this with the intent. In every field it is important, but the glory is very limited. This is nice but you don‚Äôt do things with this aim in mind\n\n\nQuestion: In one of your discoveries, did you ever feel ‚Äúthis was something I was dreaming on and I accomplished that‚Äù\n\n\nI had a few things where I was very happy. Because I had thought about it for a long time and found something new. Don‚Äôt think I had a specific time where I sat back and said this is the best discovery of their life. One should always think that the best discoveries are ahead of them.\n\n\nQuestion: What do mathematicians do after leaving research?\n\n\nSome scientists go into scientific management. Some go into industry, but this is rare. As long as what I do is what I find interesting and challenging, and what I do is not as good as my best results I would still keep doing this.\n\n\nQuestion: Does being a grandfather and becoming older change your priorities and motivation?\n\n\nYes, in general you realize you want to spend time with family, children, and grandchildren. I don‚Äôt think it comes instead of science. I hope to keep doing good work and spend time with family."
  },
  {
    "objectID": "posts/2019-09-01-shrotriya2019august19roundup/index.html#personal-blogging",
    "href": "posts/2019-09-01-shrotriya2019august19roundup/index.html#personal-blogging",
    "title": "Shamindra‚Äôs August 2019 Roundup",
    "section": "Personal Blogging",
    "text": "Personal Blogging\nBesides this post üòÑ the main things I got up to on the personal blogging front were:\n\nUpdating the distill blog settings, with a detailed step-by-step guide\n\nWrote another fun blogpost on using the tidyverse to reproduce a plot on the survivorship of the Titanic. Always so cool to be able to reproduce such famous plots using modern tools."
  },
  {
    "objectID": "posts/2019-09-01-shrotriya2019august19roundup/index.html#concluding-thoughts",
    "href": "posts/2019-09-01-shrotriya2019august19roundup/index.html#concluding-thoughts",
    "title": "Shamindra‚Äôs August 2019 Roundup",
    "section": "Concluding Thoughts",
    "text": "Concluding Thoughts\nOverall August 2019 was the end of summer and the start of a new year of graduate school - yay!\nPlease feel free to leave a comment if you found any useful articles, lectures, books, papers etc which I may find interesting."
  },
  {
    "objectID": "posts/2019-09-19-shrotriya2019september19roundup/index.html",
    "href": "posts/2019-09-19-shrotriya2019september19roundup/index.html",
    "title": "Shamindra‚Äôs September 2019 Roundup",
    "section": "",
    "text": "Welcome to the September 2019 roundup! Similar to last time I‚Äôm going to experiment with, namely documenting anything interesting I come across (articles, lectures, books, papers etc.) and any activities I get up to. This is more for my personal benefit but may also help others."
  },
  {
    "objectID": "posts/2019-09-19-shrotriya2019september19roundup/index.html#interesting-articles",
    "href": "posts/2019-09-19-shrotriya2019september19roundup/index.html#interesting-articles",
    "title": "Shamindra‚Äôs September 2019 Roundup",
    "section": "Interesting Articles",
    "text": "Interesting Articles\n\nCame across this amazing guide to reading an R help file. Experienced R users can use this fantastic pedagogical tool by Kieran Healy to teach new R users on how to read internal R help documentation.\n\nCame across this fascinating article on how calorie burning being a chess grandmaster is by Aishwarya Kumar\nKey Takeaways\n\nArticle notes that chess grandmasters can burn as much as 6000 calories individually during an intense day of sedentary chess playing!\nInitial focus is on Fabiano Caruana, an American grandmaster in chess, and current world No.¬†2. Caruana has to maintain a very strict diet and exercise routine, particularly during tournaments\nPrimary reasons for the calorie loss are heavy mental stress of the tournament, constantly thinking of chess, thus leaving limited time to think about and consume food\nInteresting quote:\n\n\n‚Ä¶India‚Äôs first grandmaster, Viswanathan Anand, does two hours of cardio each night to tire himself out so he doesn‚Äôt dream about chess\n\n\nMagnus Carlsen, reigning No.¬†1, for example consulted a professional nutritionist who recommended that he stop drinking orange juice (to avoid sugar spikes) and replace it with a less sugary regular/chocolate milk blend\nCarlsen has also optimized sitting. This is quite amazing and something to think about personally as someone who spends many hours daily in front of a screen\nCarlsen has also undertaken load management (minimizing competitions participated) to increase the amount of recuperation time between tournaments\nIn short, there are a lot of parallels to the research life which I undertake, and a lot of useful tips to optimize energy and time spent doing what I enjoy for longer\n\n\n\nThis is a really insightful interview with Hadley Wickham, a recent COPSS award winner, on the future of the R programming language:\nKey Takeaways\n\nWickham notes that R vs Python language wars are not constructive in moving data science and other fields forward.\nI agree wholeheartedly on this and firmly believe in using the best tools for the statistical job at hand. What should matter are more critical aspects like code readability, usability, and reproducibility in light of the given task\nInterestingly Wickham notes:\n\n\nA pattern that I see is that the data science team in a company uses R and the data engineering team uses Python\n\n\nWickham also has focused on bridging divides within the R community itself, namely in developing the dtplyr package to convert dplyr code to the alternative data.table package syntax. This is a promising direction ahead where tidyverse and data.table users can collaborate much more easily\nThere is also a focus on encouraging diversity in R usage and actively developing communities. He asks:\n\n\nCan we take the R-Ladies model and help other groups that are currently underserved?\n\n\nOverall it is good that Wickham was recognized recently with the famous COPSS medal in statistics and that the community is embracing software development and design as a key aspect of our profession. It seems that the future is bright for statistics!\n\n\nThis is a nice blogpost on making modular Rmarkdown files. In fact this modular Rmd approach is now used in my blog for common footer files. Did not realize how nicely the here package works with references in Rmd chunks."
  },
  {
    "objectID": "posts/2019-09-19-shrotriya2019september19roundup/index.html#interesting-presentations",
    "href": "posts/2019-09-19-shrotriya2019september19roundup/index.html#interesting-presentations",
    "title": "Shamindra‚Äôs September 2019 Roundup",
    "section": "Interesting Presentations",
    "text": "Interesting Presentations\n\n\nThis thoughtful presentation on Design at Quora by Rebecca Cox (VP of design at Quora). I‚Äôve summarized what I feel are the key points from this important presentation below.\nKey Takeaways\n\nCox notes that it is a ‚Äúgreat time to be a designer‚Äù because design has proven again and again to be a clear competitive advantage in tech\nShe notes her awareness of Quora‚Äôs apparent minimalist design interface i.e.¬†dark, red, and text heavy\nCox asks - what is Design? Some say it is the visual style, for some the user interaction, and for others ‚Äúit begins and ends with the logo‚Äù\nFor Cox, her definition is abstract, and summarized as:\n\n\nThe set of decisions about a product\n\n\nNot just an interface, logo etc. Designing is about making product decisions\nBenefits of this broad decision-driven definition for Quora are:\n\nA clear relationship between the product and the interface i.e.¬†why should a dropdown even exist?\nConcentrates attention on where it matters most i.e.¬†company goals\nEnables a role within Quora that balances authority and responsibility i.e.¬†Designers should do more than ‚Äúapply a coat of paint to a feature at the end‚Äù\n\n\nTo Cox:\n\n\nGreat design is all the work you don‚Äôt ask people who use your products to do\n\n\nThere are a lot of deep direct applications to my statistics research i.e.¬†ensure all theoretical and empirical tools are seamlessly able to be conveyed to end users in science, industry, or academia.\nI will be coming back to this over time periodically and reflect if I have undertaken this definition of design and applied it in my work and daily life\n\n\n\nThis is a really inspiring presentation on how data science is used at the ACLU specifically in the recent border immigration policies by Brooke Watson Madubuonwu.\nKey Takeaways\n\nUtilizing tidyverse to sort through messy data linkage issues in a consistent framework is well thought out by the team with useful packaged functions created for use by the wider ACLU team\nHere both statistics and law are used to tackle a major humanitarian issue i.e.¬†child border separation. This is deeply inspiring and the kind of applied work that I would like to contribute to meaningfully in the future\nI particularly appreciated the general data source skepticism showed by the ACLU team. As a statistician it is important to not only explore data but be very skeptical of the source quality i.e.¬†competing legal bodies may not provide the ACLU unbiased data!"
  },
  {
    "objectID": "posts/2019-09-19-shrotriya2019september19roundup/index.html#teaching",
    "href": "posts/2019-09-19-shrotriya2019september19roundup/index.html#teaching",
    "title": "Shamindra‚Äôs September 2019 Roundup",
    "section": "Teaching",
    "text": "Teaching\n\nI‚Äôm a TA for the amazing graduate statiscal computing course at CMU. This is an intensive (but very rewarding) programming course designed by CMU statistics professors Alex Reinhart and Chris Genovese. I highly recommend checking out this course website as a general programming reference in daily work/research. I know that I certainly will be üòÑ."
  },
  {
    "objectID": "posts/2020-01-27-shrotriya2020january20roundup/index.html",
    "href": "posts/2020-01-27-shrotriya2020january20roundup/index.html",
    "title": "Shamindra‚Äôs January 2020 Roundup",
    "section": "",
    "text": "Welcome to the January 2020 roundup! Similar to last time I‚Äôm going to experiment with documenting anything interesting I come across (articles, lectures, books, papers etc.) and any activities I get up to. This is more for my personal benefit but may also help others."
  },
  {
    "objectID": "posts/2020-01-27-shrotriya2020january20roundup/index.html#interesting-articles",
    "href": "posts/2020-01-27-shrotriya2020january20roundup/index.html#interesting-articles",
    "title": "Shamindra‚Äôs January 2020 Roundup",
    "section": "Interesting Articles",
    "text": "Interesting Articles\n\n\nCame across this nice article on R error handling. See here for the original source.\nKey Takeaways\n\nThis the latest post from the ACLU Tech & Analytics blog. This post explains the key focus of the ACLU analytics team on having clean data pipelines and using testing and assertions to facilitate this process\nUsing functions like assertthat::noNA(df$source) will return a FALSE if in fact there are no NA values in the df$source column. This seems like a very useful function to use in %>% operations in my pipelines!\nUsed in combination with assertthat::noNA(df$source) will return the actual observations that have NA values, which is super useful!\n\nThese operations are %>% friendly and can be used to verify join operations perform as expected, for example:\n\nDoes the join have the same number of rows as the original left-hand table or did the data structure of the right-hand table create new rows?\n\n\nHow much of the right-hand table of the join falls away in the left join?\n\n\n\nThese checks are notably useful for the ACLU to also check for missingness in their data pipelines. They note:\n\nA helpful check to assess whether missingness grossly misrepresents our results is to quantify the severity of the problem. What level of missingness are we willing to live with?\n\n\nThis definitely seems useful to me, as I use ad-hoc approaches to these same issues e.g.¬†na.omit without doing thorough assertions. Perhaps using this with tidylog will be useful in doing EDA. Let‚Äôs try and revisit this.\n\n\n\nThis is a really insightful article on A regular person‚Äôs guide to outbreak preparedness, by Prof.¬†Eleanor Murray:\nKey Takeaways\n\nIn the event of well publicized (ready mass hysteria) virus spreads such as the recent Coronavirus outbreak, it is important to listen to level-headed healthcare professionals. In this case it is Prof.¬†Elie Murray, an epidimiologist from Boston University\nSince I‚Äôm definitely a newbie to understanding this epidemic, I found this to be a very pragmatic guide to help prepare and prevent any further spread of such diseases\n\nIn terms of general healthy practices in the outbreak the key takeaways are to:\n\nWash your hands regularly\nFocus on improving the immune system\nTry to not catch other infections, and ensure you recover well from any existing infections\nDon‚Äôt panic\n\n\n\nIn terms of good practices to do in the event that you are sick, the key takeaways are to:\n\nStay home and recover\nCover your mouth e.g.¬†sneeze into the inner elbow\nCall a medical professional if you or a relative was in Wuhan recently\nSeek urgent medical care if you feel really sick\n\n\nPlease read the article on more detail on each of the above points and also to considerations for high risk individuals, a sick family member/friend, and if you are a healthcare responder\nOverall, great practical advice! It is great to see statisticians such as Prof.¬†Murray take the lead and address the community at large with their knowledge and expertise, when we live in an era of misinformation\nI enjoyed the emphasisis on solving this challenge (like many others) as a community"
  },
  {
    "objectID": "posts/2020-01-27-shrotriya2020january20roundup/index.html#teaching",
    "href": "posts/2020-01-27-shrotriya2020january20roundup/index.html#teaching",
    "title": "Shamindra‚Äôs January 2020 Roundup",
    "section": "Teaching",
    "text": "Teaching\n\nI‚Äôm a TA for the STAT 36-350, the undergraduate statiscal computing course at CMU. This is a welcome change of pace from my previous TA assignment taught by Prof.¬†Freeman, with whom I had the pleasure of teaching the course in Spring 2019.\nThis time we have around 150 students and, as Head-TA, I have the pleasure of managing a motivated team of 9 graduate and undergraduate TAs. Here‚Äôs to a wonderful teaching and research semester üíØ."
  },
  {
    "objectID": "posts/2021-12-31-shrotriya2021normtriconvexity/index.html",
    "href": "posts/2021-12-31-shrotriya2021normtriconvexity/index.html",
    "title": "Characterizing norm triangle inequalites via convexity",
    "section": "",
    "text": "TL;DR\nI walk through a cool and possibly less known result connecting convexity and the triangle inequalities for norms. Using this result, typical proofs of the triangle inequality for a proposed norm function are significantly simplified. This exposition is based on (Chapter 3, Robinson 2020) 1.\n(Robinson 2020) is a wonderful functional analysis book, highly recommend it üíØ!\nBackground - Norms\n Experienced readers can freely skip this Background section.\nNormed linear spaces are a natural setting for much applied mathematics and statistics. These are vector spaces, \\(V\\), endowed with a norm function, \\(\\lVert \\cdot \\rVert_{V}\\). Intuitively, norms give us a ‚Äúyardstick‚Äù to measure the ‚Äúlengths‚Äù of individual vectors in the given vector space space. A standard definition of a norm is as follows:\n\nDefinition 1 (Norms in vector spaces) For a given vector space \\(V\\), a norm \\(\\lVert \\cdot \\rVert_{V}: V \\to \\mathbb{R}\\), is a function satisfying the following three properties.\n\n\nPositive definiteness: For a \\(\\mathbf{x} \\in V\\), if \\(\\lVert \\mathbf{x} \\rVert = 0\\) then \\(\\mathbf{x} = \\mathbf{0}_{V}\\).\n\nAbsolute homogeneity: \\(\\lVert \\lambda \\mathbf{x} \\rVert = | \\lambda | \\lVert \\mathbf{x} \\rVert\\), for a \\(\\mathbf{x} \\in V, \\lambda \\in \\mathbb{R}\\).\n\nTriangle inequality: \\(\\lVert \\mathbf{x} + \\mathbf{y} \\rVert \\leq \\lVert \\mathbf{x} \\rVert + \\lVert \\mathbf{y} \\rVert\\), for a \\(\\mathbf{x}, \\mathbf{y} \\in V\\).\n\n\nWe often use many norms on a given vector space, depending on which seems ‚Äúmeaningful‚Äù for the given purpose. See here for common examples.\nRemarks\n\nRemark (Derived properties from Definition¬†1). We note that a norm, per Definition¬†1, in fact, implies the following properties:\n\nIn Definition¬†1, we can always replace positive definiteness with the stronger claim, namely that \\[\\begin{equation}\n\\text{For a $\\mathbf{x} \\in V$, if $\\lVert \\mathbf{x} \\rVert = 0 \\iff \\mathbf{x} = \\mathbf{0}_{V}$.}\n\\end{equation}\\] In short, we want to show that the reverse implication to positive definiteness always holds, i.e., \\(\\mathbf{x} = \\mathbf{0}_{V} \\implies \\lVert \\mathbf{x} \\rVert = 0\\). To prove this observe that using absolute homogeneity in Definition¬†1, we have: \\[\\begin{equation}\n\\lVert \\mathbf{x} \\rVert\n= \\lVert \\mathbf{0}_{V} \\rVert\n= \\lVert 0 (\\mathbf{0}_{V}) \\rVert\n= |0| \\lVert \\mathbf{0}_{V} \\rVert = 0\n\\end{equation}\\] As required.\nWe also have that \\(\\lVert \\mathbf{x} \\rVert \\geq 0\\), for a \\(\\mathbf{x} \\in V\\). To see this, observe that for a \\(\\mathbf{x} \\in V\\) \\[\\begin{equation}\n\\begin{split}\n0\n& = \\lVert \\mathbf{0}_{V} \\rVert\n\\quad\\text{(by previous part of this remark)}\\\\\n& = \\lVert \\mathbf{x} + (-\\mathbf{x}) \\rVert \\\\\n&\\leq \\lVert \\mathbf{x} \\rVert + \\lVert -\\mathbf{x} \\rVert\n\\quad\\text{(by the triangle inequality)} \\\\\n&= \\lVert \\mathbf{x} \\rVert +\n    \\lvert -1 \\rvert \\lVert \\mathbf{x} \\rVert\n    \\quad\\text{(by absolute homogeneity)} \\\\\n&= 2 \\lVert \\mathbf{x} \\rVert \\\\\n\\implies \\lVert \\mathbf{x} \\rVert\n& \\geq 0\n\\end{split}\n\\end{equation}\\] In effect this means the co-domain can always be changed from \\(\\lVert \\cdot \\rVert_{V}: V \\to \\mathbb{R}\\) to \\(\\lVert \\cdot \\rVert_{V}: V \\to \\mathbb{R}_{\\geq 0}\\).\nSince these can always be derived directly from Definition¬†1, as shown, we can keep Definition¬†1 in its minimal form as noted here.\nThese ideas work for seminorms as well, see here for more details.\n\n\nMain theorem\n This is based on (Lemmas 3.3-3.4 Robinson 2020).\n\nTheorem 1 (Characterization of norm triangle inequality) Let \\(N: V \\to \\mathbb{R_{\\geq 0}}\\), be a function satisfying the following two properties2.\n\n\nPositive definiteness: For a \\(\\mathbf{x} \\in V\\), if \\(N(\\mathbf{x}) = 0\\) then \\(\\mathbf{x} = \\mathbf{0}_{V}\\).\n\nAbsolute homogeneity: \\(N(\\lambda \\mathbf{x}) = | \\lambda | N(\\mathbf{x})\\), for a \\(\\mathbf{x} \\in V, \\lambda \\in \\mathbb{R}\\).\n\nWe then have that:\n\\[\n    N(\\mathbf{x} + \\mathbf{y}) \\leq N(\\mathbf{x}) + N(\\mathbf{y})\n    \\text{, for each } \\mathbf{x}, \\mathbf{y} \\in V\n    \\iff \\mathbb{B} := \\{\\mathbf{z} \\in V \\:|\\: N(\\mathbf{z}) \\leq 1 \\}\n    \\text{ is convex}\n\\tag{1}\\]\n\nIn simple terms, the importance of Theorem¬†1 (as captured by Equation¬†1) can be summarized as follows:\n\nLet \\(N : V \\to [0, \\infty)\\) be a function satisfying positive definiteness and absolute homogeneity. Then \\(N\\) satisfies the triangle inequality if and only if the unit ba induced by \\(N\\), i.e., \\(\\mathbb{B} := \\{\\mathbf{z} \\in V \\:|\\: N(\\mathbf{z}) \\leq 1 \\}\\), is a convex set.\n\nRemarks\n\nRemark. In Theorem¬†1, we note the following:\n\nThe function \\(N : V \\to \\mathbb{R}_{\\geq 0}\\), is a norm-like function, and only becomes a valid norm per Definition¬†1 once we establish the triangle inequality, i.e., \\(N(\\mathbf{x} + \\mathbf{y}) \\leq N(\\mathbf{x}) + N(\\mathbf{y})\\).\nTo prove the triangle inequality for \\(N : V \\to \\mathbb{R}_{\\geq 0}\\), the necessary condition of Theorem¬†1 to establish is: \\[\n\\mathbb{B} := \\{\\mathbf{z} \\in V \\:|\\: N(\\mathbf{z}) \\leq 1 \\}\n\\text{ is convex}\n\\tag{2}\\] which will imply the triangle inequality for \\(N\\) - huzzah!\nThe nice thing is, proving the convexity of \\(\\mathbb{B}\\) can be much easier to show than trying to prove the triangle inequality property of \\(N\\) directly, as we will soon see.\n\nSubtle point: note that here we had to assume that the co-domain of \\(N\\) is non-negative (not \\(\\mathbb{R}\\)), i.e., \\(N : V \\to \\mathbb{R}_{\\geq 0}\\). This is because in a typical norm, which satisfies the triangle inequality, is always shown to be non-negative (see remark below Definition¬†1 for more details). Here we impose non-negativity of \\(N\\) as an additional constraint to establish the triangle inequality property for \\(N\\). This is not an issue, since one would always first check the non-negativity of a candidate norm-like function \\(N\\).\n\n\nApplications: Minkowski inequalities\nBefore getting into the details of the proof, let‚Äôs just see what Theorem Theorem¬†1 can do! We‚Äôll consider two related applications taken from (Lemma 3.6, Example 3.13 Robinson 2020), respectively.\nApplication 1: \\(\\ell_{p}\\)-norm triangle inequality in \\(\\mathbb{F}^{n}\\)\n\n\nExample 1 (Minkowski inequality in finite dimensions) Let us consider \\((\\mathbb{F}^{n}, \\mathbb{F})\\), where \\(\\mathbb{F} = \\mathbb{R} \\text{ or } \\mathbb{C}\\). We then define the norm-like function \\(N_{\\ell^{p}}: \\mathbb{F}^{n} \\to \\mathbb{R}_{\\geq 0}\\):\n\\[\n    N_{\\ell^{p}}(\\mathbf{x})\n    :=\\left(\\sum_{j=1}^{n}\\left|x_{j}\\right|^{p}\\right)^{1 / p}\n    , \\quad 1 \\leq p<\\infty\n\\tag{3}\\]\n\nOne can show that \\(N_{\\ell^{p}}\\) satisfies positive definiteness and absolute homogeneity. To show that \\(N_{\\ell^{p}}\\) is a norm function we need to prove the triangle inequality. We will use Theorem¬†1. Let us define \\(\\mathbb{B} := \\{\\mathbf{z} \\in \\mathbb{F}^{n} \\:|\\: N_{\\ell^{p}}(\\mathbf{z}) \\leq 1 \\} = \\{\\mathbf{z} \\in \\mathbb{F}^{n} \\:|\\: N_{\\ell^{p}}^{p}(\\mathbf{z}) \\leq 1 \\}\\). We now need to show that \\(\\mathbb{B}\\) is convex. We will need to use the fact that for each \\(t \\in \\mathbb{R}, t \\mapsto |t|^{p}\\) is convex. Let \\(\\mathbf{x}, \\mathbf{y} \\in \\mathbb{B}\\), we then have that for \\(\\lambda \\in [0, 1]\\):\nNote: \\(t \\mapsto |t|^{p}\\), is convex, for each \\(t \\in \\mathbb{R}\\) and \\(p \\in [1, \\infty)\\). Sketch: We have, \\(|t|^{p} =: h(t) := (g \\circ f) (t)\\). Here, for each \\(x \\in \\mathbb{R}\\), we observe \\(g : x \\mapsto x^{p}\\) is increasing and convex, and \\(f : x \\mapsto |x|\\) is convex. Thus, \\(h(t) := |t|^{p}\\) is convex. \\(\\blacksquare\\)\n\\[\\begin{equation}\n\\begin{split}\n    N_{\\ell^{p}}^{p}(\\lambda \\mathbf{x} + (1 - \\lambda) \\mathbf{y})\n    & = \\sum_{j=1}^{n}|\\lambda| x_{j}|+(1-\\lambda)| y_{j}||^{p}\n    \\quad\\text{(by definition)} \\\\\n    & \\leq \\sum_{j=1}^{n} \\lambda\\left|x_{j}\\right|^{p}+(1-\\lambda)\\left|y_{j}\\right|^{p}\n    \\quad\\text{(since $t \\mapsto |t|^{p}$ is convex for each $t \\in \\mathbb{R}$)} \\\\\n    & = \\lambda \\sum_{j=1}^{n} \\left|x_{j}\\right|^{p}\n    + (1 - \\lambda) \\sum_{j=1}^{n} \\left|y_{j}\\right|^{p} \\\\\n    & \\leq 1\n    \\quad\\text{(since $\\mathbf{x}, \\mathbf{y} \\in \\mathbb{B}$.)}\n\\end{split}\n\\end{equation}\\]\nIt follows that \\(N_{\\ell^{p}}(\\lambda \\mathbf{x} + (1 - \\lambda) \\mathbf{y}) \\leq 1\\), and so \\(\\lambda \\mathbf{x} + (1 - \\lambda) \\mathbf{y} \\in \\mathbb{B}\\), as required \\(\\blacksquare\\).\nThis triangle inequality is proved in just four lines üî•!\nIn fact, since it \\(N_{\\ell^{p}}\\) satisfies the three conditions for a norm per Definition¬†1 we can now denote it using the conventional \\(\\ell_{p}\\)-norm form, i.e., \\(\\| \\mathbf{x} \\|_{\\ell^{p}} := N_{\\ell^{p}}(\\mathbf{x})\\)\nApplication 2: \\(L_{p}\\)-norm triangle inequality\nWe can also similarly prove the triangle inequality norms involving integrals efficiently. This is seen in the next example.\nHere \\(C([0, 1])\\) is the space of continuous functions on the interval \\([0, 1]\\).\n\nLet us consider \\((C([0, 1]), \\mathbb{R})\\). We then define the norm-like function \\(N_{L^{p}}: C([0, 1]) \\to \\mathbb{R}_{\\geq 0}\\):\n\\[\n    N_{L^{p}}(\\mathbf{x})\n    :=\\left(\\int_{0}^{1}\\left|f(x)\\right|^{p}\\right)^{1 / p}\n    , \\quad 1 \\leq p<\\infty\n\\tag{4}\\]\n\nLet us define \\(\\mathbb{B} := \\{h \\in C([0, 1]) \\:|\\: N_{L^{p}}(h) \\leq 1 \\} = \\{h \\in C([0, 1]) \\:|\\: N_{L^{p}}^{p}(h) \\leq 1 \\}\\). We now need to show that \\(\\mathbb{B}\\) is convex. Let \\(f, g \\in \\mathbb{B}\\), we then have that for \\(\\lambda \\in [0, 1]\\):\nOnce again, one can show that \\(N_{\\ell^{p}}\\) satisfies positive definiteness and absolute homogeneity.\n\\[\\begin{equation}\n\\begin{split}\n    N_{L^{p}}^{p}(\\lambda f + (1 - \\lambda) g)\n    & = \\int_{0}^{1}|\\lambda f(x) + (1-\\lambda) g(x)|^{p} dx\n    \\quad\\text{(by definition)} \\\\\n    & \\leq \\int_{0}^{1}\\lambda |f(x)|^{p} + (1-\\lambda) |g(x)|^{p} dx\n    \\quad\\text{(since $t \\mapsto |t|^{p}$ is convex for each $t \\in \\mathbb{R}$)} \\\\\n    & = \\lambda \\int_{0}^{1} |f(x)|^{p} dx + (1-\\lambda) \\int_{0}^{1} |g(x)|^{p} dx \\\\\n    & \\leq 1\n    \\quad\\text{(since $f, g \\in \\mathbb{B}$.)}\n\\end{split}\n\\end{equation}\\]\nIt follows that \\(N_{L^{p}}(\\lambda f + (1 - \\lambda) g) \\leq 1\\), and so \\(\\lambda f + (1 - \\lambda) g \\in \\mathbb{B}\\), as required \\(\\blacksquare\\).\nAgain, we can now denote \\(N_{L^{p}}\\) using the conventional \\(L_{p}\\)-norm form, i.e., \\(\\| f \\|_{L^{p}} := N_{L^{p}}(f)\\).\nPunchline: what did Theorem 1 buy us?\nWe just saw that applying Theorem¬†1 enabled us to write very short proofs of Minkowski‚Äôs inequality in \\(\\mathbb{F}^{n}\\) and \\(C([0, 1])\\).\nTo appreciate this approach, note that proving Minkowski‚Äôs inequality typicay requires one to first prove Young‚Äôs inequality and then H√∂lder‚Äôs inequality. Moreover these need to be done separately in \\(\\mathbb{F}^{n}\\) and \\(C([0, 1])\\). Using Theorem¬†1 aowed us to achieve both of these goals using near identical style of proofs üéâ!\nNote: The proofs of Young‚Äôs and H√∂lder‚Äôs inequality are beautiful and studying them is also insightful.\nProof of Theorem 1\nAssuming \\(N: V \\to \\mathbb{R_{\\geq 0}}\\) satisfies the two properties in Theorem Theorem¬†1, we need to prove both implications in Equation Equation¬†1.\nProof - easy direction\nAssume that \\(N(\\mathbf{x} + \\mathbf{y}) \\leq N(\\mathbf{x}) + N(\\mathbf{y})\\), for each \\(\\mathbf{x}, \\mathbf{y} \\in V\\). Let \\(\\lambda \\in [0, 1]\\) be arbitrary. We need to show that this implies for each \\(\\mathbf{x}, \\mathbf{y} \\in \\mathbb{B}\\) that the expression \\(\\lambda \\mathbf{x} + (1 - \\lambda) \\mathbf{y} \\in \\mathbb{B}\\) holds. This implies the convexity of \\(\\mathbb{B}\\).\nProof\n\nProof. (\\(\\implies\\)) We proceed directly.\nAssume that \\(N(\\mathbf{x} + \\mathbf{y}) \\leq N(\\mathbf{x}) + N(\\mathbf{y})\\), for each \\(\\mathbf{x}, \\mathbf{y} \\in V\\). Let \\(\\lambda \\in [0, 1]\\) be arbitrary. We need to show that this implies for each \\(\\mathbf{x}, \\mathbf{y} \\in \\mathbb{B}\\) that the expression \\(\\lambda \\mathbf{x} + (1 - \\lambda) \\mathbf{y} \\in \\mathbb{B}\\) holds. This implies the convexity of \\(\\mathbb{B}\\).\nWe observe that for \\(\\lambda \\in \\{0, 1\\}\\) our required expression is equal to either \\(\\mathbf{x}\\) or \\(\\mathbf{y}\\) which are both in \\(\\mathbb{B}\\), by assumption. Now fix \\(\\lambda \\in (0, 1)\\). We then note:\n\\[\\begin{equation}\n\\begin{split}\n    N(\\lambda \\mathbf{x} + (1 - \\lambda) \\mathbf{y})\n    & \\leq N(\\lambda \\mathbf{x}) + N((1 - \\lambda) \\mathbf{y})\n    \\quad\\text{($N$ satisfies triangle inequality)} \\\\\n    & = \\lvert \\lambda \\rvert N(\\mathbf{x}) + \\lvert 1 - \\lambda \\rvert N(\\mathbf{y})\n    \\quad\\text{(by absolute homogeneity of $N$)} \\\\\n    & = \\lambda N(\\mathbf{x}) + 1 - \\lambda N(\\mathbf{y})\n    \\quad\\text{(since $\\lambda > 0$)} \\\\\n    & \\leq (\\lambda) (1) + (1 - \\lambda) (1)\n    \\quad\\text{(since $N(\\mathbf{z}) \\leq 1$, for $\\mathbf{z} \\in \\mathbb{B}$)} \\\\\n    & = 1 \\\\\n\\implies \\lambda \\mathbf{x} + (1 - \\lambda) \\mathbf{y}\n    & \\in \\mathbb{B}\n\\end{split}\n\\end{equation}\\]\nWhich implies the convexity of \\(\\mathbb{B}\\), as required. \\(\\blacksquare\\)\n\nProof - interesting direction\nAssume \\(\\mathbb{B}\\) is a convex set. We need to show that this implies that \\(N(\\mathbf{x} + \\mathbf{y}) \\leq N(\\mathbf{x}) + N(\\mathbf{y})\\), for each \\(\\mathbf{x}, \\mathbf{y} \\in V\\).\nTip: In linear algebra proofs, it is best to first deal with the zero vector, \\(\\mathbf{0}_{V}\\), separately.\nProof\n\nProof. (\\(\\impliedby\\)) We proceed directly.\nAssume \\(\\mathbb{B}\\) is a convex set. We need to show that this implies that \\(N(\\mathbf{x} + \\mathbf{y}) \\leq N(\\mathbf{x}) + N(\\mathbf{y})\\), for each \\(\\mathbf{x}, \\mathbf{y} \\in V\\).\nLet \\(\\mathbf{x}, \\mathbf{y} \\in V\\). We will consider four cases.\nCase 1: Let \\(\\mathbf{x} = \\mathbf{y} = \\mathbf{0}_{V}\\). Then \\(N(\\mathbf{x}) = N(\\mathbf{y}) = N(\\mathbf{0}_{V}) = N(0 \\mathbf{0}_{V}) = |0| N(\\mathbf{0}_{V})= 0\\), by absolute homogeneity of \\(N\\). Indeed we then have that \\(N(\\mathbf{x} + \\mathbf{y}) = N(\\mathbf{0}_{V}) = 0 = N(\\mathbf{x}) + N(\\mathbf{y})\\), as required.\nCase 2: Let \\(\\mathbf{x} = \\mathbf{0}_{V}, \\mathbf{y} \\in V \\setminus \\{\\mathbf{0}_{V}\\}\\). Then \\(N(\\mathbf{y}) = 0\\), and it follows that \\(N(\\mathbf{x} + \\mathbf{y}) = N(\\mathbf{x} + \\mathbf{0}_{V}) = N(\\mathbf{x}) = N(\\mathbf{x}) + 0 = N(\\mathbf{x}) + N(\\mathbf{y})\\), as required.\nCase 3: Let \\(\\mathbf{x} \\in V \\setminus \\{\\mathbf{0}_{V}\\}, \\mathbf{y} = \\mathbf{0}_{V}\\). Same as Case 2, with the roles of \\(\\mathbf{x}, \\mathbf{y}\\) reversed.\nCase 4: Let \\(\\mathbf{x}, \\mathbf{y} \\in V \\setminus \\{\\mathbf{0}_{V}\\}\\). It then follows that \\(N(\\mathbf{x}), N(\\mathbf{y}) > 0\\), since \\(N(\\mathbf{z}) \\geq 0\\), for each \\(\\mathbf{z} \\in V\\), and \\(N(\\mathbf{z}) = 0 \\iff \\mathbf{z} = \\mathbf{0}_{V}\\). Moreover we then have that \\(\\lvert N(\\mathbf{x}) \\rvert = N(\\mathbf{x}) > 0\\) and \\(\\lvert N(\\mathbf{y}) \\rvert = N(\\mathbf{y}) > 0\\). So we can safely divide by these quantities. Let us then define \\(\\tilde{\\mathbf{x}} := \\frac{\\mathbf{x}}{N(\\mathbf{x})}, \\tilde{\\mathbf{y}} := \\frac{\\mathbf{y}}{N(\\mathbf{y})}\\). We then have by absolute homogeneity of \\(N\\) that, \\(N(\\tilde{\\mathbf{x}}) := N\\left(\\frac{\\mathbf{x}}{N(\\mathbf{x})}\\right) = \\left \\lvert \\frac{1}{N(\\mathbf{x})} \\right \\rvert N(\\mathbf{x}) = 1 \\implies \\tilde{\\mathbf{x}} \\in \\mathbb{B}\\). Similarly \\(\\tilde{\\mathbf{y}} \\in \\mathbb{B}\\). Let us denote \\(\\lambda := \\frac{N(\\mathbf{x})}{N(\\mathbf{x}) + N(\\mathbf{y})} \\in (0, 1)\\), and \\(\\mathbf{z} := \\frac{\\mathbf{x} + \\mathbf{y}}{N(\\mathbf{x}) + N(\\mathbf{y})}\\). We then have: \\[\\begin{equation}\n\\begin{split}\n    \\mathbf{z}\n    & := \\frac{\\mathbf{x} + \\mathbf{y}}{N(\\mathbf{x}) + N(\\mathbf{y})} \\\\\n    & = \\left(\\frac{N(\\mathbf{x})}{N(\\mathbf{x}) + N(\\mathbf{y})}\\right)\n        \\left(\\frac{\\mathbf{x}}{N(\\mathbf{x})}\\right) +\n        \\left(\\frac{N(\\mathbf{y})}{N(\\mathbf{x}) + N(\\mathbf{y})}\\right)\n        \\left(\\frac{\\mathbf{y}}{N(\\mathbf{y})}\\right) \\\\\n    & = \\left(\\frac{N(\\mathbf{x})}{N(\\mathbf{x}) + N(\\mathbf{y})}\\right)\n        \\tilde{\\mathbf{x}} +\n        \\left(\\frac{N(\\mathbf{y})}{N(\\mathbf{x}) + N(\\mathbf{y})}\\right)\n        \\tilde{\\mathbf{y}} \\\\\n    & = \\lambda \\tilde{\\mathbf{x}} +\n        (1 - \\lambda) \\tilde{\\mathbf{y}} \\\\\n    & \\in \\mathbb{B}\n\\end{split}\n\\end{equation}\\]\nBy the assumed convexity of \\(\\mathbb{B}\\). We then have that \\(\\mathbf{z} := \\frac{\\mathbf{x} + \\mathbf{y}}{N(\\mathbf{x}) + N(\\mathbf{y})} \\in \\mathbb{B} \\implies N(\\mathbf{z}) \\leq 1\\). We then observe: \\[\\begin{equation}\n\\begin{split}\n    N(\\mathbf{z})\n    & \\leq 1\n    \\quad\\text{(since $\\mathbf{z} \\in \\mathbb{B}$.)} \\\\\n\\iff N\\left( \\frac{\\mathbf{x} + \\mathbf{y}}{N(\\mathbf{x}) + N(\\mathbf{y})}\\right)\n    & \\leq 1\n    \\quad\\text{(by definition of $\\mathbf{z}$.)} \\\\\n\\iff \\left\\lvert \\frac{1}{N(\\mathbf{x}) + N(\\mathbf{y})}\\right\\rvert\n     N(\\mathbf{x} + \\mathbf{y})\n    & \\leq 1\n    \\quad\\text{(absolute homogeneity of $N$.)} \\\\\n\\iff \\frac{1}{N(\\mathbf{x}) + N(\\mathbf{y})}\n     N(\\mathbf{x} + \\mathbf{y})\n    & \\leq 1\n    \\quad\\text{(since $N(\\mathbf{x}), N(\\mathbf{y}) > 0$.)} \\\\\n\\iff N(\\mathbf{x} + \\mathbf{y})\n    & \\leq N(\\mathbf{x}) + N(\\mathbf{y})\n\\end{split}\n\\end{equation}\\]\nAs required. \\(\\blacksquare\\)\n\nRecap\nIn this article we learned the following about Theorem¬†1:\n\nIt gives an alternative way to characterize the triangle inequality for norm-like functions.\nUsing this characterization we can prove the triangle inequality for such norm-like functions using the convexity of the unit ba induced by such functions.\nThis is usuay easier since we have lots of tools from convex analysis to help us prove the convexity of \\(\\mathbb{B}\\).\nWe saw this in action since Theorem¬†1 enabled us to write very short proofs of Minkowski‚Äôs inequality in \\(\\mathbb{F}^{n}\\) and \\(C([0, 1])\\).\n\nIn summary, if you have a norm-like function for which you are trying to establish the triangle inequality, try out Theorem¬†1 üíØ!\nAcknowledgements\nI thank Prof.¬†James Robinson for providing several technical clarifications on Theorem¬†1. I thank Mikhail Popov for creating the wikipediapreview R package, which enable an easy interface for Wikipedia Context Cards in Rmd files. These Context Cards enable the hover over preview for Wikipedia articles. I thank Jewel Johnson for providing this helpful guide to enable fixed TOC for this article. I thank Dr.¬†Joel Nitta for providing these instructions to enable me to switch to the giscus comments system. Much of these distill site improvements were brought to our attention due to the excellent distillery site run by Prof.¬†John Paul Helveston.\n\n\n\nReferences\n\nRobinson, James C. 2020. An Introduction to Functional Analysis. Cambridge University Press.\n\nFootnotes\n\nNote: The presentation in this post is intentionay verbose. The goal is to give lots of intuition of the key result and its usefulness, and ensure that the proofs are rigorous. It is written with an empathetic mindset to newcomers, and to myself for future reference.‚Ü©Ô∏é\nWe refer to such an \\(N: V \\to \\mathbb{R_{\\geq 0}}\\) satisfying these properties, as a norm-like function.‚Ü©Ô∏é\nReusehttps://creativecommons.org/licenses/by/4.0/CitationBibTeX citation:@online{shrotriya2022,\n  author = {Shamindra Shrotriya},\n  title = {Characterizing Norm Triangle Inequalites via Convexity},\n  date = {2022-02-12},\n  url = {https://www.shamindras.com/posts/2021-12-31-shrotriya2021normtriconvexity},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nShamindra Shrotriya. 2022. ‚ÄúCharacterizing Norm Triangle\nInequalites via Convexity.‚Äù February 12, 2022. https://www.shamindras.com/posts/2021-12-31-shrotriya2021normtriconvexity."
  },
  {
    "objectID": "posts/2022-05-12-shrotriya2022sharplpnormconsts/index.html",
    "href": "posts/2022-05-12-shrotriya2022sharplpnormconsts/index.html",
    "title": "Sharp constants for finite dimensional norms",
    "section": "",
    "text": "References\n\nWendland, Holger. 2018. Numerical Linear Algebra. Cambridge Texts in Applied Mathematics. Cambridge University Press, Cambridge.\n\nFootnotes\n\nNote: The presentation in this post is intentionally verbose. The goal is to give lots of intuition of the key result and its usefulness, and ensure that the proofs are rigorous. It is written with an empathetic mindset to newcomers, and to myself for future reference.‚Ü©Ô∏é\nReusehttps://creativecommons.org/licenses/by/4.0/CitationBibTeX citation:@online{shrotriya2022,\n  author = {Shamindra Shrotriya},\n  title = {Sharp Constants for Finite Dimensional Norms},\n  date = {2022-05-12},\n  url = {https://www.shamindras.com/posts/2022-05-12-shrotriya2022sharplpnormconsts},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nShamindra Shrotriya. 2022. ‚ÄúSharp Constants for Finite Dimensional\nNorms.‚Äù May 12, 2022. https://www.shamindras.com/posts/2022-05-12-shrotriya2022sharplpnormconsts."
  },
  {
    "objectID": "posts/2022-05-12-shrotriya2022sharplpnormconsts/index.html#ell_p-norm-on-mathbbrd",
    "href": "posts/2022-05-12-shrotriya2022sharplpnormconsts/index.html#ell_p-norm-on-mathbbrd",
    "title": "Sharp constants for finite dimensional norms",
    "section": "\n\\(\\ell_{p}\\)-norm on \\(\\mathbb{R}^{d}\\)\n",
    "text": "\\(\\ell_{p}\\)-norm on \\(\\mathbb{R}^{d}\\)\n\nThroughout this presentation we will work in the finite dimensional Euclidean space \\(\\mathbb{R}^{d}\\), for some fixed \\(d \\in \\mathbb{N}\\). Moreover we will we will use the \\(\\ell_{p}\\)-norm on this space, which is defined as follows:\n\nDefinition 1 (\\(\\ell_{p}\\)-norm on \\(\\mathbb{R}^{d}\\)) For a fixed \\(p \\in [1, \\infty]\\), the \\(\\ell_{p}\\)-norm as denoted by \\(\\lVert \\cdot \\rVert_{\\ell_{p}}: \\mathbb{R}^{d} \\to \\mathbb{R}_{\\geq 0}\\), is defined as follows: \\[\n\\lVert \\mathbf{x} \\rVert_{\\ell_{p}} := \\left(\\sum_{i = 1}^{d} |x_{i} |^{p}\\right)^{\\frac{1}{p}}, \\; \\text{for each $\\mathbf{x} \\in \\mathbb{R}^{d}$}\n\\tag{1}\\]\n\nNote: Sometimes Definition¬†1 is also just called the \\(p\\)-norm in many textbooks, and has the abbreviated notation \\(\\lVert \\mathbf{x} \\rVert_{p}\\). We will use this notation going forward.\nWe note (without proof) that Definition¬†1 does indeed define a valid norm on \\(\\mathbb{R}^{d}\\). A previous post showed more of these details. A more detailed proof of this can be found in TODO."
  },
  {
    "objectID": "posts/2022-05-12-shrotriya2022sharplpnormconsts/index.html#warm-up-relationships-between-ell_1-ell_2-and-ell_infty-norms",
    "href": "posts/2022-05-12-shrotriya2022sharplpnormconsts/index.html#warm-up-relationships-between-ell_1-ell_2-and-ell_infty-norms",
    "title": "Sharp constants for finite dimensional norms",
    "section": "Warm up: Relationships between \\(\\ell_{1}, \\ell_{2}\\), and \\(\\ell_{\\infty}\\)-norms",
    "text": "Warm up: Relationships between \\(\\ell_{1}, \\ell_{2}\\), and \\(\\ell_{\\infty}\\)-norms\nOur goal will be to prove bounds for any \\(p \\in [1, \\infty]\\). However, we we get our bearings by first shifting focus on the three most commonly used \\(\\ell_{p}\\)-norms on \\(\\mathbb{R}^{d}\\). These are the \\(\\ell_{1}, \\ell_{2}\\), and \\(\\ell_{\\infty}\\)-norms. The main proposition is as follows:\n\nProposition 1 (\\(\\ell_{p}\\)-norm on \\(\\mathbb{R}^{d}\\)) For a fixed \\(p \\in [1, \\infty]\\), the \\(\\ell_{p}\\)-norm as denoted by \\(\\lVert \\cdot \\rVert_{\\ell_{p}}: \\mathbb{R}^{d} \\to \\mathbb{R}_{\\geq 0}\\), is defined as follows: \\[\n\\lVert \\mathbf{x} \\rVert_{\\ell_{p}} := \\left(\\sum_{i = 1}^{d} |x_{i} |^{p}\\right)^{\\frac{1}{p}}, \\; \\text{for each $\\mathbf{x} \\in \\mathbb{R}^{d}$}\n\\tag{2}\\]"
  },
  {
    "objectID": "posts/2019-08-21-shrotriya2019tidyfunpt2/index.html#acknowledgments",
    "href": "posts/2019-08-21-shrotriya2019tidyfunpt2/index.html#acknowledgments",
    "title": "Tidyverse Fun - Part 2",
    "section": "Acknowledgments",
    "text": "Acknowledgments\n\nI‚Äôd like to thank Salil Shrotriya for creating the preview image for this post. The hex sticker png files were sourced from here"
  },
  {
    "objectID": "posts/2019-07-15-shrotriya2019tidyfunpt1/index.html#task-1-generating-oxford-comma-triples",
    "href": "posts/2019-07-15-shrotriya2019tidyfunpt1/index.html#task-1-generating-oxford-comma-triples",
    "title": "Tidyverse Fun - Part 1",
    "section": "Task 1: Generating Oxford Comma Triples",
    "text": "Task 1: Generating Oxford Comma Triples\n\nThe central problem\nBased on a fun conversation with my statistics cohort over dinner we got to discussing the famous Oxford Comma (or Serial Comma depending on your persuasion). I‚Äôve never really adopted the use but my friends made a compelling argument on it‚Äôs apparent general lack of ambiguity when applied appropriately.\nWe will use the Oxford comma on the famously ambiguous phrase (here used without the Oxford Comma before leaves):\n\nEats, shoots and leaves\n\nAfter adding in the Oxford Comma this would become:\n\nEats, shoots, and leaves\n\nGoal: A fun experiment would be to generate all permutations of this phrase with and without the Oxford Comma using R and specifically the tidyverse packages.\n\n\nGenerating all word-triple permutations the tidy way\nFirst, let‚Äôs load our required packages.\n\nlibrary(knitr)\nlibrary(magrittr)\nlibrary(tidyverse)\nlibrary(glue)\n\nLet‚Äôs also define our unique global word values used to construct the required phrases:\n\nWORD_VALS <- c(\"eats\", \"shoots\", \"leaves\")\n\nGenerate all unique 3-word permutations without replacement from the three unique words. We‚Äôll create a helper function to check that a vector of words is unique.\n\nis_unq_perm <- function(word1, word2, word3){\n    words_vec <- c(word1, word2, word3)\n    return(length(words_vec) - length(unique(words_vec)) == 0)\n}\n\nWe can now simply generate every possible triple with replacement using the tidyr::crossing function. We proceed to filter these \\(3^3 = 27\\) triples for unique triples using our is_unq_perm helper function applied row-by-row using purrr::pmap_lgl. The _lgl simply returns a TRUE/FALSE logical value as intended by the applied function.\n\nNote: The tidyr::crossing generates a Cartesian product of all the 3 word triples, very handy\n\n\n# Generate the unique word-triples\nall_perms <- tidyr::crossing(word1 = WORD_VALS,\n                             word2 = WORD_VALS,\n                             word3 = WORD_VALS) %>%\n                mutate(.data = .,\n                       is_unq_perm = purrr::pmap_lgl(.l = .,\n                                                     is_unq_perm)) %>%\n                filter(.data = ., is_unq_perm) %>%\n                select(-is_unq_perm)\n\n# Display output in a nice centered table\nall_perms %>%\n  kable(x = ., align = 'c',\n        col.names = c(\"Word 1\",\n                      \"Word 2\",\n                      \"Word 3\"))\n\n\n\n\nWord 1\nWord 2\nWord 3\n\n\n\n\neats\nleaves\nshoots\n\n\neats\nshoots\nleaves\n\n\nleaves\neats\nshoots\n\n\nleaves\nshoots\neats\n\n\nshoots\neats\nleaves\n\n\nshoots\nleaves\neats\n\n\n\n\n\nGreat - that part is done! Now we just need to generate for each triple of words an oxford comma and non-oxford comma version. This is done easily using the amazing glue package as seen below:\n\nexprs <- all_perms %>%\n          mutate(non_oxford_comma =\n                   glue_data(.x = .,\n                             \"{word1}, {word2} and {word3}\"),\n                 oxford_comma =\n                   glue_data(.x = .,\n                             \"{word1}, {word2}, and {word3}\")) %>%\n          select(non_oxford_comma, oxford_comma)\n\nWe can display the side-by-side output of the Non-Oxford Comma vs.¬†Oxford comma for the \\(6\\) generated triples as follows:\n\n# Display output in a nice centered table\nexprs %>%\n  kable(x = .,\n        align = 'c',\n        col.names = c(\"Non-Oxford Comma\",\n                      \"Oxford Comma\"))\n\n\n\n\nNon-Oxford Comma\nOxford Comma\n\n\n\n\neats, leaves and shoots\neats, leaves, and shoots\n\n\neats, shoots and leaves\neats, shoots, and leaves\n\n\nleaves, eats and shoots\nleaves, eats, and shoots\n\n\nleaves, shoots and eats\nleaves, shoots, and eats\n\n\nshoots, eats and leaves\nshoots, eats, and leaves\n\n\nshoots, leaves and eats\nshoots, leaves, and eats\n\n\n\n\n\nSo there you have it. Have fun generating your own version of Oxford Comma triples to engage in civil discussions with your fellow grammar focused friends üòÑ."
  },
  {
    "objectID": "research.html",
    "href": "research.html",
    "title": "Research",
    "section": "",
    "text": "I‚Äôm a final year PhD candidate in the Department of Statistics and Data Science at Carnegie Mellon University. I‚Äôm extremely fortunate to be advised by Prof.¬†Matey Neykov.\nBroadly speaking my primary research interests lie in studying various generalizations in classical statistics, and their theoretical properties, through a modern lens.\nMy thesis covers topics including density estimation, isotonic regression, and location-scale estimation. I‚Äôm also actively interested in statistical ranking (in particular the Bradley-Terry-Luce model), and spatiotemporal modeling (wildfire prediction).\nI particularly enjoy the collaborative aspect of research, and I‚Äôm privileged to work with the following brilliant people1: Heejong Bong, Niccol√≤ (Nic) Dalmasso, Riccardo Fogliato, Arun Kumar Kuchibhotla, Wanshan Li, Matey Neykov, Alessandro (Ale) Rinaldo.\nI recommend just perusing some of my papers below to get a better idea of the type of problems I like to work on, and the style of papers I enjoy writing with my co-authors. If you‚Äôd like to work on a problem together, feel free to reach out."
  },
  {
    "objectID": "research.html#publications",
    "href": "research.html#publications",
    "title": "Research",
    "section": "Publications",
    "text": "Publications\n\nPublished\n\n\nUnder Review\n\n\nWorkshops and Competitions"
  },
  {
    "objectID": "research.html#published",
    "href": "research.html#published",
    "title": "Research",
    "section": "Published",
    "text": "Published"
  },
  {
    "objectID": "research.html#under-review",
    "href": "research.html#under-review",
    "title": "Research",
    "section": "Under Review",
    "text": "Under Review\nRevisiting Le Cam‚Äôs Equation: Exact Minimax Rates over Convex Density Classes  Shamindra Shrotriya, Matey Neykov (2022).\n arxiv  pdf   abstract\n\nWe study the classical problem of deriving minimax rates for density estimation over convex density classes. Building on the pioneering work of Le Cam (1973), Birge (1983, 1986), Wong and Shen (1995), Yang and Barron (1999), we determine the exact (up to constants) minimax rate over any convex density class. This work thus extends these known results by demonstrating that the local metric entropy of the density class always captures the minimax optimal rates under such settings. Our bounds provide a unifying perspective across both parametric and nonparametric convex density classes, under weaker assumptions on the richness of the density class than previously considered. Our proposed ‚Äòmultistage sieve‚Äô MLE applies to any such convex density class. We apply our risk bounds to rederive known minimax rates including bounded total variation, and Holder density classes. We further illustrate the utility of the result by deriving upper bounds for less studied classes, e.g., convex mixture of densities."
  },
  {
    "objectID": "research.html#workshops-and-competitions",
    "href": "research.html#workshops-and-competitions",
    "title": "Research",
    "section": "Workshops and Competitions",
    "text": "Workshops and Competitions"
  }
]