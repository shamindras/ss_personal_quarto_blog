{
  "hash": "a8e79d139c9155a35a0fee99517b07d5",
  "result": {
    "markdown": "---\ntitle: \"Tidyverse Fun - Part 1\"\ndescription: |\n  First part in a series of doing useful tasks with\n  the `tidyverse`. This time, we generate Oxford Comma\n  triples, and sequentially numbered BibTeX\n  entries\ncategories: [tidyverse, rstats]\ndate: \"2019-07-15\"\nimage: images/logo-01.jpg\nslug: shrotriya2019tidyfunpt1\nbibliography: ../../refs.bib\nformat: \n  html:\n    code-link: true\nexecute:\n  echo: true\neditor_options: \n  markdown: \n    wrap: 80\n---\n\n\n\n\n## Task 1: Generating Oxford Comma Triples\n\n### The central problem\n\nBased on a fun conversation with my statistics cohort over dinner we got to\ndiscussing the famous [*Oxford\nComma*](https://en.wikipedia.org/wiki/Serial_comma){.wiki} (or *Serial Comma*\ndepending on your persuasion). I've never really adopted the use but my friends\nmade a compelling argument on it's apparent general lack of ambiguity when\napplied appropriately.\n\nWe will use the Oxford comma on the famously *ambiguous* phrase (here used\nwithout the Oxford Comma before _leaves_):\n\n> Eats, shoots and leaves\n\nAfter adding in the Oxford Comma this would become:\n\n> Eats, shoots, and leaves\n\n**Goal:** A fun experiment would be to generate *all permutations* of this\nphrase with and without the Oxford Comma using `R` and specifically the\n`tidyverse` packages.\n\n### Generating all word-triple permutations the `tidy` way\n\nFirst, let's load our required packages.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(knitr)\nlibrary(magrittr)\nlibrary(tidyverse)\nlibrary(glue)\n```\n:::\n\n\nLet's also define our unique global word values used to construct the required\nphrases:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nWORD_VALS <- c(\"eats\", \"shoots\", \"leaves\")\n```\n:::\n\n\nGenerate all unique 3-word permutations _without replacement_ from the three\nunique words. We'll create a helper function to check that a vector of words is\nunique.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nis_unq_perm <- function(word1, word2, word3){\n    words_vec <- c(word1, word2, word3)\n    return(length(words_vec) - length(unique(words_vec)) == 0)\n}\n```\n:::\n\n\nWe can now simply generate every possible triple _with replacement_ using the\n`tidyr::crossing` function.  We proceed to _filter_ these $3^3 = 27$ triples\nfor unique triples using our `is_unq_perm` helper function applied _row-by-row_\nusing `purrr::pmap_lgl`. The `_lgl` simply returns a `TRUE/FALSE` logical value\nas intended by the applied function.\n\n<aside> __Note:__ The `tidyr::crossing` generates a *Cartesian product* of all\nthe 3 word triples, very handy</aside>\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Generate the unique word-triples\nall_perms <- tidyr::crossing(word1 = WORD_VALS,\n                             word2 = WORD_VALS,\n                             word3 = WORD_VALS) %>%\n                mutate(.data = .,\n                       is_unq_perm = purrr::pmap_lgl(.l = .,\n                                                     is_unq_perm)) %>%\n                filter(.data = ., is_unq_perm) %>%\n                select(-is_unq_perm)\n\n# Display output in a nice centered table\nall_perms %>%\n  kable(x = ., align = 'c',\n        col.names = c(\"Word 1\",\n                      \"Word 2\",\n                      \"Word 3\"))\n```\n\n::: {.cell-output-display}\n| Word 1 | Word 2 | Word 3 |\n|:------:|:------:|:------:|\n|  eats  | leaves | shoots |\n|  eats  | shoots | leaves |\n| leaves |  eats  | shoots |\n| leaves | shoots |  eats  |\n| shoots |  eats  | leaves |\n| shoots | leaves |  eats  |\n:::\n:::\n\n\nGreat - that part is done! Now we just need to generate for each triple of\nwords an oxford comma and non-oxford comma version. This is done easily using\nthe amazing `glue` package as seen below:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nexprs <- all_perms %>%\n          mutate(non_oxford_comma =\n                   glue_data(.x = .,\n                             \"{word1}, {word2} and {word3}\"),\n                 oxford_comma =\n                   glue_data(.x = .,\n                             \"{word1}, {word2}, and {word3}\")) %>%\n          select(non_oxford_comma, oxford_comma)\n```\n:::\n\n\nWe can display the side-by-side output of the Non-Oxford Comma vs. Oxford comma\nfor the $6$ generated triples as follows:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Display output in a nice centered table\nexprs %>%\n  kable(x = .,\n        align = 'c',\n        col.names = c(\"Non-Oxford Comma\",\n                      \"Oxford Comma\"))\n```\n\n::: {.cell-output-display}\n|    Non-Oxford Comma     |       Oxford Comma       |\n|:-----------------------:|:------------------------:|\n| eats, leaves and shoots | eats, leaves, and shoots |\n| eats, shoots and leaves | eats, shoots, and leaves |\n| leaves, eats and shoots | leaves, eats, and shoots |\n| leaves, shoots and eats | leaves, shoots, and eats |\n| shoots, eats and leaves | shoots, eats, and leaves |\n| shoots, leaves and eats | shoots, leaves, and eats |\n:::\n:::\n\n\nSo there you have it. Have fun generating your own version of Oxford Comma\ntriples to engage in civil discussions with your fellow grammar focused friends\nüòÑ.\n\n## Task 2: Generating Sequentially Numbered BibTeX Entries\n\n### The central problem\n\nIn this case I needed to generate several BibTeX entries of the form:\n\n```markup\n@misc{doe2019_lec1,\nauthor        = {Doe, John},\ntitle         = {Lecture Note 1 - STAT10A},\nmonth         = {March},\nyear          = {2018},\nurl           = {https://statschool/~doe/stats10A/Lectures/Lecture01.pdf},\n}\n```\n\nAs it can be seen the lectures are numbered sequentially and change in the main\nBibTeX `id`, the `title`, and the `url` field.\n\nSpecifically I needed to construct 30 such sequential entries for lectures\n`1-30`. Rather than do this manually, I realized that this would be fun\nscripting exercise with using the `tidyverse` packages `glue`, `purrr`, and\n`stringr`.\n\n**Goal:** Create 30 such BibTeX entries and print to the console to\ndirectly-copy paste to my BibTeX file.\n\n### The `tidy` approach\n\nFirst step is to write a function that takes a lecture number (integer) as an\ninput and then outputs a single BibTeX entry for that lecture.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Generate BibTeX entry for a single lecture number\nget_lec_bibtex <- function(lec_num){\n  # Get the 2 character padded lecture number i.e. 1 -> \"01\"\n  lec_num_pad <- str_pad(string = lec_num, width = 2,\n                         side = \"left\", pad = \"0\")\n\n  # Construct the BibTeX entry\n  out_bbtex_str <- glue(\n    \"@misc{doe2019_lec<lec_num>,\n    author = {Doe, John},\n    title  = {Lecture Note <lec_num> - STAT10A},\n    month  = {March},\n    year   = {2018},\n    url    = {https://www.hpg/~doe/st10A/lecs/lec<lec_num_pad>.pdf}}\",\n    .open = \"<\",\n    .close = \">\")\n\n  return(out_bbtex_str)\n}\n```\n:::\n\n\nNote that by default `glue` allows you to substitute input text in between `{`\nand `}` markers. However BibTeX entries *already have* literal default `{}`\ntags that we need to include in our function output. Rather than escaping them\nthe `glue` package conveniently allows us to change the default opening and\nclosing markers üíØ! We simply set these to be angle\nbrackets `< >` using the `.open` and `.close` options above.\n\n<aside> __Note:__ Luckily we don't have _literal_ angle brackets in our BibTeX\noutput to deal with here</aside>\n\nLet's just test this out quickly:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlec_no <- 1\nget_lec_bibtex(lec_num = lec_no)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n@misc{doe2019_lec1,\nauthor = {Doe, John},\ntitle  = {Lecture Note 1 - STAT10A},\nmonth  = {March},\nyear   = {2018},\nurl    = {https://www.hpg/~doe/st10A/lecs/lec01.pdf}}\n```\n:::\n:::\n\n\nGreat - looks like it is working as required with the correct string padding in\nthe lecture number in the pdf filename!\n\n<aside> **Note:** We used the `stringr` `str_pad` to convert `1` to `\"01\"`\n</aside>\n\n### Apply to all lectures using `purrr`\n\nLet's finish this by creating all the entries using `purrr`:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlec_nums <- c(1, 30)\nlec_nums %>%\n  map_chr(.x = ., .f = ~get_lec_bibtex(lec_num = .x)) %>%\n  cat(., sep = \"\\n\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n@misc{doe2019_lec1,\nauthor = {Doe, John},\ntitle  = {Lecture Note 1 - STAT10A},\nmonth  = {March},\nyear   = {2018},\nurl    = {https://www.hpg/~doe/st10A/lecs/lec01.pdf}}\n\n@misc{doe2019_lec30,\nauthor = {Doe, John},\ntitle  = {Lecture Note 30 - STAT10A},\nmonth  = {March},\nyear   = {2018},\nurl    = {https://www.hpg/~doe/st10A/lecs/lec30.pdf}}\n```\n:::\n:::\n\n\nYay - this works as expected! We can now paste into BibTeX as required.\n\nNote that we only created it for lectures 1 and 30 for easy scrolling. But for\nall lectures we can just replace `c(1, 30)` with `1:30` in the above code.\n\n## Conclusion\n\nThis post was for me to document and serve as a guide to automating a couple of\nfun text-based tasks that I came across in my work (and social life!). Using\nthe `tidy` framework can be a fun way to solve these tasks (but certainly not\nthe only way in `R`). Have fun playing around with the above and please post in\nthe comments any questions/feedback you may have üëç.\n\nStay tuned for more blogposts solving more such tasks.\n\n## Acknowledgments {.appendix}\n\nI'd like to thank Salil Shrotriya for creating the preview image for this post.\nThe hex sticker `png` files were sourced from\n[here](https://github.com/rstudio/hex-stickers)\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}